@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{perez2022red,
  title={Red teaming language models with language models},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2202.03286},
  year={2022}
}

@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022}
}

@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shah2023scalable,
  title={Scalable and transferable black-box jailbreaks for language models via persona modulation},
  author={Shah, Rusheb and Pour, Soroush and Tagade, Arush and Casper, Stephen and Rando, Javier and others},
  journal={arXiv preprint arXiv:2311.03348},
  year={2023}
}

@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}

@inproceedings{bierbaumer2018smashing,
  title={Smashing the stack protector for fun and profit},
  author={Bierbaumer, Bruno and Kirsch, Julian and Kittel, Thomas and Francillon, Aur{\'e}lien and Zarras, Apostolis},
  booktitle={ICT Systems Security and Privacy Protection: 33rd IFIP TC 11 International Conference, SEC 2018, Held at the 24th IFIP World Computer Congress, WCC 2018, Poznan, Poland, September 18-20, 2018, Proceedings 33},
  pages={293--306},
  year={2018},
  organization={Springer}
}

@inproceedings{zou2024improving,
  title={Improving alignment and robustness with circuit breakers},
  author={Zou, Andy and Phan, Long and Wang, Justin and Duenas, Derek and Lin, Maxwell and Andriushchenko, Maksym and Kolter, J Zico and Fredrikson, Matt and Hendrycks, Dan},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{arditi2024refusal,
  title={Refusal in language models is mediated by a single direction},
  author={Arditi, Andy and Obeso, Oscar and Syed, Aaquib and Paleka, Daniel and Panickssery, Nina and Gurnee, Wes and Nanda, Neel},
  journal={arXiv preprint arXiv:2406.11717},
  year={2024}
}

@article{qi2023fine,
  title={Fine-tuning aligned language models compromises safety, even when users do not intend to!},
  author={Qi, Xiangyu and Zeng, Yi and Xie, Tinghao and Chen, Pin-Yu and Jia, Ruoxi and Mittal, Prateek and Henderson, Peter},
  journal={arXiv preprint arXiv:2310.03693},
  year={2023}
}

@inproceedings{anil2024many,
  title={Many-shot jailbreaking},
  author={Anil, Cem and Durmus, Esin and Rimsky, Nina and Sharma, Mrinank and Benton, Joe and Kundu, Sandipan and Batson, Joshua and Tong, Meg and Mu, Jesse and Ford, Daniel J and others},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{casper2024defending,
  title={Defending Against Unforeseen Failure Modes with Latent Adversarial Training},
  author={Casper, Stephen and Schulze, Lennart and Patel, Oam and Hadfield-Menell, Dylan},
  journal={arXiv preprint arXiv:2403.05030},
  year={2024}
}

@article{debenedetti2024agentdojo,
  title={AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents},
  author={Debenedetti, Edoardo and Zhang, Jie and Balunovi{\'c}, Mislav and Beurer-Kellner, Luca and Fischer, Marc and Tram{\`e}r, Florian},
  journal={arXiv preprint arXiv:2406.13352},
  year={2024}
}

@article{schaeffer2024universal,
  title={When Do Universal Image Jailbreaks Transfer Between Vision-Language Models?},
  author={Schaeffer, Rylan and Valentine, Dan and Bailey, Luke and Chua, James and Eyzaguirre, Crist{\'o}bal and Durante, Zane and Benton, Joe and Miranda, Brando and Sleight, Henry and Hughes, John and others},
  journal={arXiv preprint arXiv:2407.15211},
  year={2024}
}

@article{rando2024gradient,
  title={Gradient-based Jailbreak Images for Multimodal Fusion Models},
  author={Rando, Javier and Korevaar, Hannah and Brinkman, Erik and Evtimov, Ivan and Tram{\`e}r, Florian},
  journal={arXiv preprint arXiv:2410.03489},
  year={2024}
}

@inproceedings{carlini2017adversarial,
  title={Adversarial examples are not easily detected: Bypassing ten detection methods},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={Proceedings of the 10th ACM workshop on artificial intelligence and security},
  pages={3--14},
  year={2017}
}

@article{qi2024ai,
  title={AI Risk Management Should Incorporate Both Safety and Security},
  author={Qi, Xiangyu and Huang, Yangsibo and Zeng, Yi and Debenedetti, Edoardo and Geiping, Jonas and He, Luxi and Huang, Kaixuan and Madhushani, Udari and Sehwag, Vikash and Shi, Weijia and others},
  journal={arXiv preprint arXiv:2405.19524},
  year={2024}
}

@article{anwar2024foundational,
  title={Foundational challenges in assuring alignment and safety of large language models},
  author={Anwar, Usman and Saparov, Abulhair and Rando, Javier and Paleka, Daniel and Turpin, Miles and Hase, Peter and Lubana, Ekdeep Singh and Jenner, Erik and Casper, Stephen and Sourbut, Oliver and others},
  journal={arXiv preprint arXiv:2404.09932},
  year={2024}
}

@article{rando2025adversarial,
  title={Adversarial ML Problems Are Getting Harder to Solve and to Evaluate},
  author={Rando, Javier and Zhang, Jie and Carlini, Nicholas and Tram{\`e}r, Florian},
  journal={arXiv preprint arXiv:2502.02260},
  year={2025}
}
