
@article{baevski_wav2vec_2020,
	title = {wav2vec 2.0: A framework for self-supervised learning of speech representations},
	journaltitle = {Proc. of {NeurIPS}},
	author = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
	date = {2020},
}

@article{hsu_hubert_2021,
	title = {Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
	volume = {29},
	pages = {3451--3460},
	journaltitle = {{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing},
	author = {Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
	date = {2021},
	note = {Publisher: {IEEE}},
}

@article{chen_wavlm_2022,
	title = {Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
	volume = {16},
	pages = {1505--1518},
	number = {6},
	journaltitle = {{IEEE} Journal of Selected Topics in Signal Processing},
	author = {Chen, Sanyuan and {others}},
	date = {2022},
	note = {Publisher: {IEEE}},
}

@article{borsos_audiolm_2023,
	title = {Audiolm: a language modeling approach to audio generation},
	volume = {31},
	pages = {2523--2533},
	journaltitle = {{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing},
	author = {Borsos, Zalán and {others}},
	date = {2023},
	note = {Publisher: {IEEE}},
}

@article{rubenstein_audiopalm_2023,
	title = {{AudioPaLM}: A Large Language Model That Can Speak and Listen},
	journaltitle = {{arXiv} preprint {arXiv}:2306.12925},
	author = {Rubenstein, Paul K and {others}},
	date = {2023},
}

@article{chen_lauragpt_2023,
	title = {Lauragpt: Listen, attend, understand, and regenerate audio with gpt},
	journaltitle = {{arXiv} preprint {arXiv}:2310.04673},
	author = {Chen, Qian and {others}},
	date = {2023},
}

@article{wang_viola_2023,
	title = {{VioLA}: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation},
	journaltitle = {{arXiv} preprint {arXiv}:2305.16107},
	author = {Wang, Tianrui and {others}},
	date = {2023},
}

@misc{gemini-team_gemini_2023,
	title = {Gemini: A Family of Highly Capable Multimodal Models},
	author = {{Gemini-Team}},
	date = {2023},
	note = {\_eprint: 2312.11805},
}

@article{busso_iemocap_2008,
	title = {{IEMOCAP}: Interactive emotional dyadic motion capture database},
	volume = {42},
	pages = {335--359},
	journaltitle = {Language resources and evaluation},
	author = {Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S},
	date = {2008},
	note = {Publisher: Springer},
}

@inproceedings{abrevaya_effective_2023,
	title = {Effective Latent Differential Equation Models via Attention and Multiple Shooting},
	booktitle = {The Symbiosis of Deep Learning and Differential Equations {III}},
	author = {Abrevaya, Germán and Ramezanian-Panahi, Mahta and Gagnon-Audet, Jean-Christophe and Polosecki, Pablo and Rish, Irina and Dawson, Silvina Ponce and Cecchi, Guillermo and Dumas, Guillaume},
	date = {2023},
}

@article{obeid_temple_2016,
	title = {The temple university hospital {EEG} data corpus},
	volume = {10},
	pages = {195498},
	journaltitle = {Frontiers in neuroscience},
	author = {Obeid, Iyad and Picone, Joseph},
	date = {2016},
	note = {Publisher: Frontiers},
}

@article{alexander_open_2017,
	title = {An open resource for transdiagnostic research in pediatric mental health and learning disorders},
	volume = {4},
	pages = {1--26},
	number = {1},
	journaltitle = {Scientific data},
	author = {Alexander, Lindsay M and Escalera, Jasmine and Ai, Lei and Andreotti, Charissa and Febre, Karina and Mangone, Alexander and Vega-Potler, Natan and Langer, Nicolas and Alexander, Alexis and Kovacs, Meagan and {others}},
	date = {2017},
	note = {Publisher: Nature Publishing Group},
}

@article{tadel_brainstorm_2011,
	title = {Brainstorm: a user-friendly application for {MEG}/{EEG} analysis},
	volume = {2011},
	pages = {1--13},
	journaltitle = {Computational intelligence and neuroscience},
	author = {Tadel, François and Baillet, Sylvain and Mosher, John C and Pantazis, Dimitrios and Leahy, Richard M},
	date = {2011},
	note = {Publisher: Hindawi Limited London, {UK}, United Kingdom},
}

@article{hyvarinen_unsupervised_2016,
	title = {Unsupervised feature extraction by time-contrastive learning and nonlinear ica},
	volume = {29},
	journaltitle = {Advances in neural information processing systems},
	author = {Hyvarinen, Aapo and Morioka, Hiroshi},
	date = {2016},
}

@article{raut_arousal_2023,
	title = {Arousal as a universal embedding for spatiotemporal brain dynamics},
	pages = {2023--11},
	journaltitle = {{bioRxiv}},
	author = {Raut, Ryan V and Rosenthal, Zachary P and Wang, Xiaodan and Miao, Hanyang and Zhang, Zhanqi and Lee, Jin-Moo and Raichle, Marcus E and Bauer, Adam Q and Brunton, Steven L and Brunton, Bingni W and {others}},
	date = {2023},
	note = {Publisher: Cold Spring Harbor Laboratory},
}

@misc{ito_lj_2017,
	title = {The {LJ} Speech Dataset},
	url = {https://keithito.com/LJ-Speech-Dataset/},
	author = {Ito, Keith},
	date = {2017},
}

@misc{gagnon-audet_woods_2023,
	title = {{WOODS}: Benchmarks for Out-of-Distribution Generalization in Time Series},
	author = {Gagnon-Audet, Jean-Christophe and Ahuja, Kartik and Darvishi-Bayazi, Mohammad-Javad and Mousavi, Pooneh and Dumas, Guillaume and Rish, Irina},
	date = {2023},
	note = {\_eprint: 2203.09978},
}

@misc{scholkopf_towards_2021,
	title = {Towards Causal Representation Learning},
	author = {Schölkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},
	date = {2021},
	note = {\_eprint: 2102.11107},
}

@article{vosoughi_learning_2024,
	title = {Learning Audio Concepts from Counterfactual Natural Language},
	journaltitle = {{arXiv} preprint {arXiv}:2401.04935},
	author = {Vosoughi, Ali and Bondi, Luca and Wu, Ho-Hsiang and Xu, Chenliang},
	date = {2024},
}

@article{jas_reproducible_2018,
	title = {A reproducible {MEG}/{EEG} group study with the {MNE} software: recommendations, quality assessments, and good practices},
	volume = {12},
	pages = {345102},
	journaltitle = {Frontiers in neuroscience},
	author = {Jas, Mainak and Larson, Eric and Engemann, Denis A and Leppäkangas, Jaakko and Taulu, Samu and Hämäläinen, Matti and Gramfort, Alexandre},
	date = {2018},
	note = {Publisher: Frontiers},
}

@article{rolls_automated_2020,
	title = {Automated anatomical labelling atlas 3},
	volume = {206},
	pages = {116189},
	journaltitle = {Neuroimage},
	author = {Rolls, Edmund T and Huang, Chu-Chung and Lin, Ching-Po and Feng, Jianfeng and Joliot, Marc},
	date = {2020},
	note = {Publisher: Elsevier},
}

@article{gramfort_meg_2013,
	title = {{MEG} and {EEG} Data Analysis with {MNE}-Python},
	volume = {7},
	doi = {10.3389/fnins.2013.00267},
	pages = {1--13},
	number = {267},
	journaltitle = {Frontiers in Neuroscience},
	author = {Gramfort, Alexandre and Luessi, Martin and Larson, Eric and Engemann, Denis A. and Strohmeier, Daniel and Brodbeck, Christian and Goj, Roman and Jas, Mainak and Brooks, Teon and Parkkonen, Lauri and Hämäläinen, Matti S.},
	date = {2013},
}

@article{rafiei_self-supervised_2024,
	title = {Self-Supervised Learning for Electroencephalography},
	volume = {35},
	doi = {10.1109/TNNLS.2022.3190448},
	pages = {1457--1471},
	number = {2},
	journaltitle = {{IEEE} Transactions on Neural Networks and Learning Systems},
	author = {Rafiei, Mohammad H. and Gauthier, Lynne V. and Adeli, Hojjat and Takabi, Daniel},
	date = {2024},
	keywords = {machine learning, Machine learning, Electroencephalography, Brain modeling, Data models, Training, Electroencephalography ({EEG}), Heuristic algorithms, self-supervised learning ({SSL}), Task analysis},
}

@misc{eastwood_dci-es_2023,
	title = {{DCI}-{ES}: An Extended Disentanglement Framework with Connections to Identifiability},
	url = {http://arxiv.org/abs/2210.00364},
	doi = {10.48550/arXiv.2210.00364},
	shorttitle = {{DCI}-{ES}},
	abstract = {In representation learning, a common approach is to seek representations which disentangle the underlying factors of variation. Eastwood \& Williams (2018) proposed three metrics for quantifying the quality of such disentangled representations: disentanglement (D), completeness (C) and informativeness (I). In this work, we first connect this {DCI} framework to two common notions of linear and nonlinear identifiability, thereby establishing a formal link between disentanglement and the closely-related field of independent component analysis. We then propose an extended {DCI}-{ES} framework with two new measures of representation quality - explicitness (E) and size (S) - and point out how D and C can be computed for black-box predictors. Our main idea is that the functional capacity required to use a representation is an important but thus-far neglected aspect of representation quality, which we quantify using explicitness or ease-of-use (E). We illustrate the relevance of our extensions on the {MPI}3D and Cars3D datasets.},
	number = {{arXiv}:2210.00364},
	publisher = {{arXiv}},
	author = {Eastwood, Cian and Nicolicioiu, Andrei Liviu and Kügelgen, Julius von and Kekić, Armin and Träuble, Frederik and Dittadi, Andrea and Schölkopf, Bernhard},
	urldate = {2024-11-22},
	date = {2023-02-16},
	eprinttype = {arxiv},
	eprint = {2210.00364},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:C\:\\Users\\mahta\\Zotero\\storage\\XPTPMPGV\\Eastwood et al. - 2023 - DCI-ES An Extended Disentanglement Framework with.pdf:application/pdf;Snapshot:C\:\\Users\\mahta\\Zotero\\storage\\VD4I2XST\\2210.html:text/html},
}

@article{trauble_disentangled_nodate,
	title = {On Disentangled Representations Learned from Correlated Data},
	author = {Träuble, Frederik and Creager, Elliot and Kilbertus, Niki and Locatello, Francesco and Dittadi, Andrea and Goyal, Anirudh and Schölkopf, Bernhard and Bauer, Stefan},
	langid = {english},
	file = {Träuble et al. - On Disentangled Representations Learned from Corre.pdf:C\:\\Users\\mahta\\Zotero\\storage\\M99RR2TS\\Träuble et al. - On Disentangled Representations Learned from Corre.pdf:application/pdf},
}

@misc{tejada-lapuerta_causal_2023,
	title = {Causal machine learning for single-cell genomics},
	url = {http://arxiv.org/abs/2310.14935},
	doi = {10.48550/arXiv.2310.14935},
	abstract = {Advances in single-cell omics allow for unprecedented insights into the transcription profiles of individual cells. When combined with large-scale perturbation screens, through which specific biological mechanisms can be targeted, these technologies allow for measuring the effect of targeted perturbations on the whole transcriptome. These advances provide an opportunity to better understand the causative role of genes in complex biological processes such as gene regulation, disease progression or cellular development. However, the high-dimensional nature of the data, coupled with the intricate complexity of biological systems renders this task nontrivial. Within the machine learning community, there has been a recent increase of interest in causality, with a focus on adapting established causal techniques and algorithms to handle high-dimensional data. In this perspective, we delineate the application of these methodologies within the realm of single-cell genomics and their challenges. We first present the model that underlies most of current causal approaches to single-cell biology and discuss and challenge the assumptions it entails from the biological point of view. We then identify open problems in the application of causal approaches to single-cell data: generalising to unseen environments, learning interpretable models, and learning causal models of dynamics. For each problem, we discuss how various research directions - including the development of computational approaches and the adaptation of experimental protocols - may offer ways forward, or on the contrary pose some difficulties. With the advent of single cell atlases and increasing perturbation data, we expect causal models to become a crucial tool for informed experimental design.},
	number = {{arXiv}:2310.14935},
	publisher = {{arXiv}},
	author = {Tejada-Lapuerta, Alejandro and Bertin, Paul and Bauer, Stefan and Aliee, Hananeh and Bengio, Yoshua and Theis, Fabian J.},
	urldate = {2024-11-22},
	date = {2023-10-23},
	eprinttype = {arxiv},
	eprint = {2310.14935},
	keywords = {Computer Science - Machine Learning, Quantitative Biology - Genomics},
	file = {Preprint PDF:C\:\\Users\\mahta\\Zotero\\storage\\HI4NT3LL\\Tejada-Lapuerta et al. - 2023 - Causal machine learning for single-cell genomics.pdf:application/pdf;Snapshot:C\:\\Users\\mahta\\Zotero\\storage\\H8N9W33Y\\2310.html:text/html},
}
