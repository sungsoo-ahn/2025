@misc{mathieu_introduction_2024,
  title   = {An Introduction to Flow Matching},
  author  = {Fjelde, Tor and Mathieu, Emile and Dutordoir, Vincent},
  journal = {https://mlg.eng.cam.ac.uk/blog/},
  year    = {2024},
  month   = {January},
  url     = {https://mlg.eng.cam.ac.uk/blog/2024/01/20/flow-matching.html}
}

@inproceedings{xiao2021tackling,
  title     = {Tackling the generative learning trilemma with denoising diffusion gans},
  author    = {Xiao, Zhisheng and Kreis, Karsten and Vahdat, Arash},
  booktitle = {ICLR},
  year      = {2022}
}

@inproceedings{rezende2015variational,
  title     = {Variational inference with normalizing flows},
  author    = {Rezende, Danilo and Mohamed, Shakir},
  booktitle = {ICML},
  pages     = {1530--1538},
  year      = {2015}
}

@article{tabak2013family,
  title     = {A family of nonparametric density estimation algorithms},
  author    = {Tabak, Esteban G and Turner, Cristina V},
  journal   = {Communications on Pure and Applied Mathematics},
  volume    = {66},
  number    = {2},
  pages     = {145--164},
  year      = {2013},
  publisher = {Wiley Online Library}
}

@inproceedings{dinh2017density,
  title     = {Density estimation using Real NVP},
  author    = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  booktitle = {ICLR},
  year      = {2017}
}


@article{papamakarios2021normalizing,
  title   = {Normalizing flows for probabilistic modeling and inference},
  author  = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal = {JMLR},
  volume  = {22},
  number  = {57},
  pages   = {1--64},
  year    = {2021}
}

@article{chen2018neural,
  title   = {Neural ordinary differential equations},
  author  = {Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  journal = {Advances in neural information processing systems},
  volume  = {31},
  year    = {2018}
}

@inproceedings{behrmann2019invertible,
  title     = {Invertible residual networks},
  author    = {Behrmann, Jens and Grathwohl, Will and Chen, Ricky TQ and Duvenaud, David and Jacobsen, J{\"o}rn-Henrik},
  booktitle = {ICML},
  year      = {2019}
}

@article{tomczak2016improving,
  title   = {Improving variational auto-encoders using householder flow},
  author  = {Tomczak, Jakub M and Welling, Max},
  journal = {arXiv preprint arXiv:1611.09630},
  year    = {2016}
}

@inproceedings{kingma2016improved,
  title   = {Improved variational inference with inverse autoregressive flow},
  author  = {Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
  journal = {NeurIPS},
  year    = {2016}
}

@inproceedings{van2018sylvester,
  title     = {Sylvester normalizing flows for variational inference},
  author    = {Van Den Berg, Rianne and Hasenclever, Leonard and Tomczak, Jakub M and Welling, Max},
  booktitle = {UAI},
  year      = {2018},
  url       = {https://arxiv.org/abs/1803.05649}
}

@inproceedings{draxler2024free,
  title     = {Free-form flows: Make any architecture a normalizing flow},
  author    = {Draxler, Felix and Sorrenson, Peter and Zimmermann, Lea and Rousselot, Armand and K{\"o}the, Ullrich},
  booktitle = {AISTATS},
  pages     = {2197--2205},
  year      = {2024}
}


@inproceedings{grathwohl2018ffjord,
  title     = {FFJORD: Free-form continuous dynamics for scalable reversible generative models},
  author    = {Grathwohl, Will and Chen, Ricky TQ and Bettencourt, Jesse and Sutskever, Ilya and Duvenaud, David},
  booktitle = {ICLR},
  year      = {2019},
  url       = {https://openreview.net/forum?id=rJxgknCcK7}
}


@inproceedings{albergo_building_2023,
  title     = {Building Normalizing Flows with Stochastic Interpolants},
  booktitle = {ICLR},
  author    = {Albergo, Michael Samuel and Vanden-Eijnden, Eric},
  year      = {2023},
  url       = {https://openreview.net/forum?id=li7qeBbCR1t}
}

@inproceedings{liu_flow_2023,
  title     = {Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow},
  booktitle = {ICLR},
  author    = {Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  year      = {2023},
  url       = {https://openreview.net/forum?id=XVjTT1nw5z}
}

@inproceedings{lipman_flow_2023,
  title     = {Flow Matching for Generative Modeling},
  author    = {Lipman, Yaron and Chen, Ricky T. Q. and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  year      = {2023},
  url       = {https://openreview.net/forum?id=PqvMRDCJT9t},
  booktitle = {ICLR}
}

@article{tong_improving_2024,
  title    = {Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport},
  author   = {Tong, Alexander and Fatras, Kilian and Malkin, Nikolay and Huguet, Guillaume and Zhang, Yanlei and {Rector-Brooks}, Jarrid and Wolf, Guy and Bengio, Yoshua},
  year     = {2024},
  journal  = {Transactions on Machine Learning Research},
  issn     = {2835-8856},
  url      = {https://openreview.net/forum?id=CD9Snc73AW},
  urldate  = {2024-10-30},
  abstract = {Continuous normalizing flows (CNFs) are an attractive generative modeling technique, but they have been held back by limitations in their simulation-based maximum likelihood training. We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs. CFM features a stable regression objective like that used to train the stochastic flow in diffusion models but enjoys the efficient inference of deterministic flow models. In contrast to both diffusion models and prior CNF training algorithms, CFM does not require the source distribution to be Gaussian or require evaluation of its density. A variant of our objective is optimal transport CFM (OT-CFM), which creates simpler flows that are more stable to train and lead to faster inference, as evaluated in our experiments. Furthermore, we show that when the true OT plan is available, our OT-CFM method approximates dynamic OT. Training CNFs with CFM improves results on a variety of conditional and unconditional generation tasks, such as inferring single cell dynamics, unsupervised image translation, and Schr{\"o}dinger bridge inference. The Python code is available at https://github.com/atong01/conditional-flow-matching.},
  langid   = {english},
  file     = {/home/twilight/Zotero/storage/FSKT9MEQ/Tong et al. - 2023 - Improving and generalizing flow-based generative models with minibatch optimal transport.pdf}
}


@article{pooladian23ot,
  title    = {Multisample Flow Matching: Straightening Flows with Minibatch Couplings},
  abstract = {Simulation-free methods for training continuous-time generative models construct probability paths that go between noise distributions and individual data samples. Recent works, such as Flow Matching, derived paths that are optimal for each data sample. However, these algorithms rely on independent data and noise samples, and do not exploit underlying structure in the data distribution for constructing probability paths. We propose Multisample Flow Matching, a more general framework that uses non-trivial couplings between data and noise samples while satisfying the correct marginal constraints. At very small overhead costs, this generalization allows us to (i) reduce gradient variance during training, (ii) obtain straighter flows for the learned vector field, which allows us to generate high-quality samples using fewer function evaluations, and (iii) obtain transport maps with lower cost in high dimensions, which has applications beyond generative modeling. Importantly, we do so in a completely simulation-free manner with a simple minimization objective. We show that our proposed methods improve sample consistency on downsampled ImageNet data sets, and lead to better low-cost sample generation.},
  author   = {Pooladian, {Aram Alexandre} and Heli Ben-Hamu and Carles Domingo-Enrich and Brandon Amos and Yaron Lipman and Chen, {Ricky T.Q.}},
  year     = {2023},
  language = {English},
  volume   = {202},
  pages    = {28100--28127},
  journal  = {Proceedings of Machine Learning Research},
  issn     = {2640-3498},
  note     = {40th International Conference on Machine Learning, ICML 2023 ; Conference date: 23-07-2023 Through 29-07-2023}
}

@inproceedings{kornilov2024optimal,
  title     = {Optimal Flow Matching: Learning Straight Trajectories in Just One Step},
  author    = {Nikita Maksimovich Kornilov and Petr Mokrov and Alexander Gasnikov and Alexander Korotin},
  booktitle = {The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year      = {2024},
  url       = {https://openreview.net/forum?id=kqmucDKVcU}
}

@article{tong2024improving,
  title   = {Improving and generalizing flow-based generative models with minibatch optimal transport},
  author  = {Alexander Tong and Kilian FATRAS and Nikolay Malkin and Guillaume Huguet and Yanlei Zhang and Jarrid Rector-Brooks and Guy Wolf and Yoshua Bengio},
  journal = {Transactions on Machine Learning Research},
  issn    = {2835-8856},
  year    = {2024},
  url     = {https://openreview.net/forum?id=CD9Snc73AW},
  note    = {Expert Certification}
}


@inproceedings{liu2023flow,
  title     = {Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow},
  author    = {Xingchao Liu and Chengyue Gong and qiang liu},
  booktitle = {The Eleventh International Conference on Learning Representations },
  year      = {2023},
  url       = {https://openreview.net/forum?id=XVjTT1nw5z}
}

@book{ambrosio2008gradient,
  title={Gradient flows: in metric spaces and in the space of probability measures},
  author={Ambrosio, Luigi and Gigli, Nicola and Savar{\'e}, Giuseppe},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@article{song2021maximum,
  title={Maximum likelihood training of score-based diffusion models},
  author={Song, Yang and Durkan, Conor and Murray, Iain and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1415--1428},
  year={2021}
}

@Article{zhang2024flow,
  author  = {Zhang, Yasi and Yu, Peiyu and Zhu, Yaxuan and Chang, Yingshan and Gao, Feng and Wu, Ying Nian and Leong, Oscar},
  journal = {arXiv preprint arXiv:2405.18816},
  title   = {Flow priors for linear inverse problems via iterative corrupted trajectory matching},
  year    = {2024},
  file    = {:TheÌ€se/bibliographie/stage\:these/Zhang_2024_flow.pdf:PDF},
}
