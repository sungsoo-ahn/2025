@article{gregor2015draw,
  title={DRAW: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint, arXiv:1502.04623},
  year={2015},
  url={https://arxiv.org/pdf/1502.04623.pdf}
}

@article{fort2019deep,
  title={Deep ensembles: A loss landscape perspective},
  author={Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02757},
  year={2019},
  url = {https://arxiv.org/abs/1912.02757}
}

@article{hansen1990neural,
  title={Neural network ensembles},
  author={Hansen, Lars Kai and Salamon, Peter},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={12},
  number={10},
  pages={993--1001},
  year={1990},
  publisher={IEEE},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=58871}
}

@article{klabunde2023similarity,
  title={Similarity of neural network models: A survey of functional and representational measures},
  author={Klabunde, Max and Schumacher, Tobias and Strohmaier, Markus and Lemmerich, Florian},
  journal={arXiv preprint arXiv:2305.06329},
  year={2023}, 
  url = {https://arxiv.org/pdf/2305.06329}
}

@article{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018},
  url= {https://proceedings.neurips.cc/paper_files/paper/2018/file/a41b3bb3e6b050b6c9067c67f663b915-Paper.pdf}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada},
  url = {https://www.cs.toronto.edu/~kriz/cifar.html}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020},
  url = {https://arxiv.org/pdf/2010.11929}
}

@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  url ={https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf},
  year={2008}
}


@article{lin1991divergence,
  title={Divergence measures based on the Shannon entropy},
  author={Lin, Jianhua},
  journal={IEEE Transactions on Information theory},
  volume={37},
  number={1},
  pages={145--151},
  year={1991},
  publisher={IEEE},
  url = {https://ieeexplore.ieee.org/document/61115}
}


@article{mead1992review,
  title={Review of the development of multidimensional scaling methods},
  author={Mead, Al},
  journal={Journal of the Royal Statistical Society: Series D (The Statistician)},
  volume={41},
  number={1},
  pages={27--39},
  year={1992},
  publisher={Wiley Online Library},
  url = {}
}

@article{pearson1901liii,
  title={LIII. On lines and planes of closest fit to systems of points in space},
  author={Pearson, Karl},
  journal={The London, Edinburgh, and Dublin philosophical magazine and journal of science},
  volume={2},
  number={11},
  pages={559--572},
  year={1901},
  publisher={Taylor \& Francis}
}


@inproceedings{10.5555/2980539.2980616, author = {Belkin, Mikhail and Niyogi, Partha}, title = {Laplacian eigenmaps and spectral techniques for embedding and clustering}, year = {2001}, publisher = {MIT Press}, address = {Cambridge, MA, USA}, abstract = {Drawing on the correspondence between the graph Laplacian, the Laplace-Beltrami operator on a manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for constructing a representation for data sampled from a low dimensional manifold embedded in a higher dimensional space. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality preserving properties and a natural connection to clustering. Several applications are considered.}, booktitle = {Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic}, pages = {585â€“591}, numpages = {7}, location = {Vancouver, British Columbia, Canada}, series = {NIPS'01} }

@inproceedings{chundawat2023can,
author = {Chundawat, Vikram S and Tarun, Ayush K and Mandal, Murari and Kankanhalli, Mohan},
title = {Can bad teaching induce forgetting? unlearning in deep networks using an incompetent teacher},
year = {2023},
isbn = {978-1-57735-880-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v37i6.25879},
doi = {10.1609/aaai.v37i6.25879},
abstract = {Machine unlearning has become an important area of research due to an increasing need for machine learning (ML) applications to comply with the emerging data privacy regulations. It facilitates the provision for removal of certain set or class of data from an already trained ML model without requiring retraining from scratch. Recently, several efforts have been put in to make unlearning to be effective and efficient. We propose a novel machine unlearning method by exploring the utility of competent and incompetent teachers in a student-teacher framework to induce forgetfulness. The knowledge from the competent and incompetent teachers is selectively transferred to the student to obtain a model that doesn't contain any information about the forget data. We experimentally show that this method generalizes well, is fast and effective. Furthermore, we introduce the zero retrain forgetting (ZRF) metric to evaluate any unlearning method. Unlike the existing unlearning metrics, the ZRF score does not depend on the availability of the expensive retrained model. This makes it useful for analysis of the unlearned model after deployment as well. We present results of experiments conducted for random subset forgetting and class forgetting on various deep networks and across different application domains.},
booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {810},
numpages = {8},
series = {AAAI'23/IAAI'23/EAAI'23}
}