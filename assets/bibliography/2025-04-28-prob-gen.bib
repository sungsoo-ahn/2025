@ARTICLE{nihNatureProtein,
  title     = "Nature of the protein universe",
  author    = "Levitt, Michael",
  abstract  = "The protein universe is the set of all proteins of all
               organisms. Here, all currently known sequences are analyzed in
               terms of families that have single-domain or multidomain
               architectures and whether they have a known three-dimensional
               structure. Growth of new single-domain families is very slow:
               Almost all growth comes from new multidomain architectures that
               are combinations of domains characterized by approximately
               15,000 sequence profiles. Single-domain families are mostly
               shared by the major groups of organisms, whereas multidomain
               architectures are specific and account for species diversity.
               There are known structures for a quarter of the single-domain
               families, and >70\% of all sequences can be partially modeled
               thanks to their membership in these families.",
  journal   = "Proc. Natl. Acad. Sci. U. S. A.",
  publisher = "Proceedings of the National Academy of Sciences",
  volume    =  106,
  number    =  27,
  pages     = "11079--11084",
  month     =  jul,
  year      =  2009,
  language  = "en"
}


@ARTICLE{nihDarwinianEvolution,
  title     = "Darwinian evolution can follow only very few mutational paths to
               fitter proteins",
  author    = "Weinreich, Daniel M and Delaney, Nigel F and Depristo, Mark A
               and Hartl, Daniel L",
  abstract  = "Five point mutations in a particular beta-lactamase allele
               jointly increase bacterial resistance to a clinically important
               antibiotic by a factor of approximately 100,000. In principle,
               evolution to this high-resistance beta-lactamase might follow
               any of the 120 mutational trajectories linking these alleles.
               However, we demonstrate that 102 trajectories are inaccessible
               to Darwinian selection and that many of the remaining
               trajectories have negligible probabilities of realization,
               because four of these five mutations fail to increase drug
               resistance in some combinations. Pervasive biophysical
               pleiotropy within the beta-lactamase seems to be responsible,
               and because such pleiotropy appears to be a general property of
               missense mutations, we conclude that much protein evolution will
               be similarly constrained. This implies that the protein tape of
               life may be largely reproducible and even predictable.",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science (AAAS)",
  volume    =  312,
  number    =  5770,
  pages     = "111--114",
  month     =  apr,
  year      =  2006,
  language  = "en"
}


@ARTICLE{natureHighlyAccurate,
  title     = "Highly accurate protein structure prediction with {AlphaFold}",
  author    = "Jumper, John and Evans, Richard and Pritzel, Alexander and
               Green, Tim and Figurnov, Michael and Ronneberger, Olaf and
               Tunyasuvunakool, Kathryn and Bates, Russ and {\v Z}{\'\i}dek,
               Augustin and Potapenko, Anna and Bridgland, Alex and Meyer,
               Clemens and Kohl, Simon A A and Ballard, Andrew J and Cowie,
               Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and
               Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen,
               Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal
               and Steinegger, Martin and Pacholska, Michalina and Berghammer,
               Tamas and Bodenstein, Sebastian and Silver, David and Vinyals,
               Oriol and Senior, Andrew W and Kavukcuoglu, Koray and Kohli,
               Pushmeet and Hassabis, Demis",
  abstract  = "Proteins are essential to life, and understanding their
               structure can facilitate a mechanistic understanding of their
               function. Through an enormous experimental effort1-4, the
               structures of around 100,000 unique proteins have been
               determined5, but this represents a small fraction of the
               billions of known protein sequences6,7. Structural coverage is
               bottlenecked by the months to years of painstaking effort
               required to determine a single protein structure. Accurate
               computational approaches are needed to address this gap and to
               enable large-scale structural bioinformatics. Predicting the
               three-dimensional structure that a protein will adopt based
               solely on its amino acid sequence-the structure prediction
               component of the 'protein folding problem'8-has been an
               important open research problem for more than 50 years9. Despite
               recent progress10-14, existing methods fall far short of atomic
               accuracy, especially when no homologous structure is available.
               Here we provide the first computational method that can
               regularly predict protein structures with atomic accuracy even
               in cases in which no similar structure is known. We validated an
               entirely redesigned version of our neural network-based model,
               AlphaFold, in the challenging 14th Critical Assessment of
               protein Structure Prediction (CASP14)15, demonstrating accuracy
               competitive with experimental structures in a majority of cases
               and greatly outperforming other methods. Underpinning the latest
               version of AlphaFold is a novel machine learning approach that
               incorporates physical and biological knowledge about protein
               structure, leveraging multi-sequence alignments, into the design
               of the deep learning algorithm.",
  journal   = "Nature",
  publisher = "Springer Science and Business Media LLC",
  volume    =  596,
  number    =  7873,
  pages     = "583--589",
  month     =  aug,
  year      =  2021,
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en"
}


@ARTICLE{nihEvolutionbasedModel,
  title     = "An evolution-based model for designing chorismate mutase enzymes",
  author    = "Russ, William P and Figliuzzi, Matteo and Stocker, Christian and
               Barrat-Charlaix, Pierre and Socolich, Michael and Kast, Peter
               and Hilvert, Donald and Monasson, Remi and Cocco, Simona and
               Weigt, Martin and Ranganathan, Rama",
  abstract  = "The rational design of enzymes is an important goal for both
               fundamental and practical reasons. Here, we describe a process
               to learn the constraints for specifying proteins purely from
               evolutionary sequence data, design and build libraries of
               synthetic genes, and test them for activity in vivo using a
               quantitative complementation assay. For chorismate mutase, a key
               enzyme in the biosynthesis of aromatic amino acids, we
               demonstrate the design of natural-like catalytic function with
               substantial sequence diversity. Further optimization focuses the
               generative model toward function in a specific genomic context.
               The data show that sequence-based statistical models suffice to
               specify proteins and provide access to an enormous space of
               functional sequences. This result provides a foundation for a
               general process for evolution-based design of artificial
               proteins.",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science (AAAS)",
  volume    =  369,
  number    =  6502,
  pages     = "440--445",
  month     =  jul,
  year      =  2020,
  copyright = "https://www.sciencemag.org/about/science-licenses-journal-article-reuse",
  language  = "en"
}


@ARTICLE{natureUnifiedRational,
  title     = "Unified rational protein engineering with sequence-based deep
               representation learning",
  author    = "Alley, Ethan C and Khimulya, Grigory and Biswas, Surojit and
               AlQuraishi, Mohammed and Church, George M",
  abstract  = "Rational protein engineering requires a holistic understanding
               of protein function. Here, we apply deep learning to unlabeled
               amino-acid sequences to distill the fundamental features of a
               protein into a statistical representation that is semantically
               rich and structurally, evolutionarily and biophysically
               grounded. We show that the simplest models built on top of this
               unified representation (UniRep) are broadly applicable and
               generalize to unseen regions of sequence space. Our data-driven
               approach predicts the stability of natural and de novo designed
               proteins, and the quantitative function of molecularly diverse
               mutants, competitively with the state-of-the-art methods. UniRep
               further enables two orders of magnitude efficiency improvement
               in a protein engineering task. UniRep is a versatile summary of
               fundamental protein features that can be applied across protein
               engineering informatics.",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  16,
  number    =  12,
  pages     = "1315--1322",
  month     =  dec,
  year      =  2019,
  language  = "en"
}


@misc{riesselman2017deepgenerativemodelsgenetic,
      title={Deep generative models of genetic variation capture mutation effects}, 
      author={Adam J. Riesselman and John B. Ingraham and Debora S. Marks},
      year={2017},
      eprint={1712.06527},
      archivePrefix={arXiv},
      primaryClass={q-bio.QM},
      url={https://arxiv.org/abs/1712.06527}, 
}

@inproceedings{NEURIPS2020_4c5bcfec,
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {6840--6851},
 publisher = {Curran Associates, Inc.},
 title = {Denoising Diffusion Probabilistic Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
 volume = {33},
 year = {2020}
}

@misc{rao2019evaluatingproteintransferlearning,
      title={Evaluating Protein Transfer Learning with TAPE}, 
      author={Roshan Rao and Nicholas Bhattacharya and Neil Thomas and Yan Duan and Xi Chen and John Canny and Pieter Abbeel and Yun S. Song},
      year={2019},
      eprint={1906.08230},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1906.08230}, 
}

@misc{elnaggar2021prottranscrackinglanguagelifes,
      title={ProtTrans: Towards Cracking the Language of Life's Code Through Self-Supervised Deep Learning and High Performance Computing}, 
      author={Ahmed Elnaggar and Michael Heinzinger and Christian Dallago and Ghalia Rihawi and Yu Wang and Llion Jones and Tom Gibbs and Tamas Feher and Christoph Angerer and Martin Steinegger and Debsindhu Bhowmik and Burkhard Rost},
      year={2021},
      eprint={2007.06225},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.06225}, 
}

@article{louis,
author = {Iain G. Johnston  and Kamaludin Dingle  and Sam F. Greenbury  and Chico Q. Camargo  and Jonathan P. K. Doye  and Sebastian E. Ahnert  and Ard A. Louis },
title = {Symmetry and simplicity spontaneously emerge from the algorithmic nature of evolution},
journal = {Proceedings of the National Academy of Sciences},
volume = {119},
number = {11},
pages = {e2113883119},
year = {2022},
doi = {10.1073/pnas.2113883119},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2113883119},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2113883119},
abstract = {Why does evolution favor symmetric structures when they only represent a minute subset of all possible forms? Just as monkeys randomly typing into a computer language will preferentially produce outputs that can be generated by shorter algorithms, so the coding theorem from algorithmic information theory predicts that random mutations, when decoded by the process of development, preferentially produce phenotypes with shorter algorithmic descriptions. Since symmetric structures need less information to encode, they are much more likely to appear as potential variation. Combined with an arrival-of-the-frequent mechanism, this algorithmic bias predicts a much higher prevalence of low-complexity (high-symmetry) phenotypes than follows from natural selection alone and also explains patterns observed in protein complexes, RNA secondary structures, and a gene regulatory network. Engineers routinely design systems to be modular and symmetric in order to increase robustness to perturbations and to facilitate alterations at a later date. Biological structures also frequently exhibit modularity and symmetry, but the origin of such trends is much less well understood. It can be tempting to assume—by analogy to engineering design—that symmetry and modularity arise from natural selection. However, evolution, unlike engineers, cannot plan ahead, and so these traits must also afford some immediate selective advantage which is hard to reconcile with the breadth of systems where symmetry is observed. Here we introduce an alternative nonadaptive hypothesis based on an algorithmic picture of evolution. It suggests that symmetric structures preferentially arise not just due to natural selection but also because they require less specific information to encode and are therefore much more likely to appear as phenotypic variation through random mutations. Arguments from algorithmic information theory can formalize this intuition, leading to the prediction that many genotype–phenotype maps are exponentially biased toward phenotypes with low descriptional complexity. A preference for symmetry is a special case of this bias toward compressible descriptions. We test these predictions with extensive biological data, showing that protein complexes, RNA secondary structures, and a model gene regulatory network all exhibit the expected exponential bias toward simpler (and more symmetric) phenotypes. Lower descriptional complexity also correlates with higher mutational robustness, which may aid the evolution of complex modular assemblies of multiple components.}}


@article {Anishchenko2020.07.22.211482,
	author = {Anishchenko, Ivan and Chidyausiku, Tamuka M. and Ovchinnikov, Sergey and Pellock, Samuel J. and Baker, David},
	title = {De novo protein design by deep network hallucination},
	elocation-id = {2020.07.22.211482},
	year = {2020},
	doi = {10.1101/2020.07.22.211482},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {There has been considerable recent progress in protein structure prediction using deep neural networks to infer distance constraints from amino acid residue co-evolution1{\textendash}3. We investigated whether the information captured by such networks is sufficiently rich to generate new folded proteins with sequences unrelated to those of the naturally occuring proteins used in training the models. We generated random amino acid sequences, and input them into the trRosetta structure prediction network to predict starting distance maps, which as expected are quite featureless. We then carried out Monte Carlo sampling in amino acid sequence space, optimizing the contrast (KL-divergence) between the distance distributions predicted by the network and the background distribution. Optimization from different random starting points resulted in a wide range of proteins with diverse sequences and all alpha, all beta sheet, and mixed alpha-beta structures. We obtained synthetic genes encoding 129 of these network hallucinated sequences, expressed and purified the proteins in E coli, and found that 27 folded to monomeric stable structures with circular dichroism spectra consistent with the hallucinated structures. Thus deep networks trained to predict native protein structures from their sequences can be inverted to design new proteins, and such networks and methods should contribute, alongside traditional physically based models, to the de novo design of proteins with new functions.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/07/23/2020.07.22.211482},
	eprint = {https://www.biorxiv.org/content/early/2020/07/23/2020.07.22.211482.full.pdf},
	journal = {bioRxiv}
}

@inproceedings{NEURIPS2019_f3a4ff48,
 author = {Ingraham, John and Garg, Vikas and Barzilay, Regina and Jaakkola, Tommi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generative Models for Graph-Based Protein Design},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/f3a4ff4839c56a5f460c88cce3666a2b-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{WU202118,
title = {Protein sequence design with deep generative models},
journal = {Current Opinion in Chemical Biology},
volume = {65},
pages = {18-27},
year = {2021},
note = {Mechanistic Biology * Machine Learning in Chemical Biology},
issn = {1367-5931},
doi = {https://doi.org/10.1016/j.cbpa.2021.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S136759312100051X},
author = {Zachary Wu and Kadina E. Johnston and Frances H. Arnold and Kevin K. Yang},
keywords = {Deep learning, Generative models, Protein engineering},
abstract = {Protein engineering seeks to identify protein sequences with optimized properties. When guided by machine learning, protein sequence generation methods can draw on prior knowledge and experimental efforts to improve this process. In this review, we highlight recent applications of machine learning to generate protein sequences, focusing on the emerging field of deep generative methods.}
}

@misc{fu2023latentdiffusionmodelprotein,
      title={A Latent Diffusion Model for Protein Structure Generation}, 
      author={Cong Fu and Keqiang Yan and Limei Wang and Wing Yee Au and Michael McThrow and Tao Komikado and Koji Maruhashi and Kanji Uchino and Xiaoning Qian and Shuiwang Ji},
      year={2023},
      eprint={2305.04120},
      archivePrefix={arXiv},
      primaryClass={q-bio.BM},
      url={https://arxiv.org/abs/2305.04120}, 
}

@article {Zhang2023.12.13.571602,
	author = {Zhang, Yuyang and Ma, Zinnia and Gong, Haipeng},
	title = {TopoDiff: Improving Protein Backbone Generation with Topology-aware Latent Encoding},
	elocation-id = {2023.12.13.571602},
	year = {2023},
	doi = {10.1101/2023.12.13.571602},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {The de novo design of protein structures is an intriguing research topic in the field of protein engineering. Recent breakthroughs in diffusion-based generative models have demonstrated substantial promise in tackling this task, notably in the generation of diverse and realistic protein structures. While existing models predominantly focus on unconditional generation or fine-grained conditioning at the residue level, the holistic, top-down approaches to control the overall topological arrangements are still insufficiently explored. In response, we introduce TopoDiff, a diffusion-based framework augmented by a global-structure encoding module, which is capable of unsupervisedly learning a compact latent representation of natural protein topologies with interpretable characteristics and simultaneously harnessing this learned information for controllable protein structure generation. We also propose a novel metric specifically designed to assess the coverage of sampled proteins with respect to the natural protein space. In comparative analyses with existing models, our generative model not only demonstrates comparable performance on established metrics but also exhibits better coverage across the recognized topology landscape. In summary, TopoDiff emerges as a novel solution towards enhancing the controllability and comprehensiveness of de novo protein structure generation, presenting new possibilities for innovative applications in protein engineering and beyond.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2023/12/14/2023.12.13.571602},
	eprint = {https://www.biorxiv.org/content/early/2023/12/14/2023.12.13.571602.full.pdf},
	journal = {bioRxiv}
}

@ARTICLE{Watson2023-eb,
  title     = "De novo design of protein structure and function with
               {RFdiffusion}",
  author    = "Watson, Joseph L and Juergens, David and Bennett, Nathaniel R
               and Trippe, Brian L and Yim, Jason and Eisenach, Helen E and
               Ahern, Woody and Borst, Andrew J and Ragotte, Robert J and
               Milles, Lukas F and Wicky, Basile I M and Hanikel, Nikita and
               Pellock, Samuel J and Courbet, Alexis and Sheffler, William and
               Wang, Jue and Venkatesh, Preetham and Sappington, Isaac and
               Torres, Susana V{\'a}zquez and Lauko, Anna and De Bortoli,
               Valentin and Mathieu, Emile and Ovchinnikov, Sergey and
               Barzilay, Regina and Jaakkola, Tommi S and DiMaio, Frank and
               Baek, Minkyung and Baker, David",
  abstract  = "There has been considerable recent progress in designing new
               proteins using deep-learning methods1-9. Despite this progress,
               a general deep-learning framework for protein design that
               enables solution of a wide range of design challenges, including
               de novo binder design and design of higher-order symmetric
               architectures, has yet to be described. Diffusion models10,11
               have had considerable success in image and language generative
               modelling but limited success when applied to protein modelling,
               probably due to the complexity of protein backbone geometry and
               sequence-structure relationships. Here we show that by
               fine-tuning the RoseTTAFold structure prediction network on
               protein structure denoising tasks, we obtain a generative model
               of protein backbones that achieves outstanding performance on
               unconditional and topology-constrained protein monomer design,
               protein binder design, symmetric oligomer design, enzyme active
               site scaffolding and symmetric motif scaffolding for therapeutic
               and metal-binding protein design. We demonstrate the power and
               generality of the method, called RoseTTAFold diffusion
               (RFdiffusion), by experimentally characterizing the structures
               and functions of hundreds of designed symmetric assemblies,
               metal-binding proteins and protein binders. The accuracy of
               RFdiffusion is confirmed by the cryogenic electron microscopy
               structure of a designed binder in complex with influenza
               haemagglutinin that is nearly identical to the design model. In
               a manner analogous to networks that produce images from
               user-specified inputs, RFdiffusion enables the design of diverse
               functional proteins from simple molecular specifications.",
  journal   = "Nature",
  publisher = "Springer Science and Business Media LLC",
  volume    =  620,
  number    =  7976,
  pages     = "1089--1100",
  month     =  aug,
  year      =  2023,
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en"
}
