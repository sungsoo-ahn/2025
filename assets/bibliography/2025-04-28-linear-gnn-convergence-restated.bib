@inproceedings{Xu2021,
  author       = {Keyulu Xu and
                  Mozhi Zhang and
                  Stefanie Jegelka and
                  Kenji Kawaguchi},
  editor       = {Marina Meila and
                  Tong Zhang},
  title        = {Optimization of Graph Neural Networks: Implicit Acceleration by Skip
                  Connections and More Depth},
  booktitle    = {Proceedings of the 38th International Conference on Machine Learning,
                  {ICML} 2021, 18-24 July 2021, Virtual Event},
  series       = {Proceedings of Machine Learning Research},
  volume       = {139},
  pages        = {11592--11602},
  publisher    = {{PMLR}},
  year         = {2021},
  url          = {http://proceedings.mlr.press/v139/xu21k.html},
  timestamp    = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/XuZJK21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Saxe2013,
  author       = {Andrew M. Saxe and
                  James L. McClelland and
                  Surya Ganguli},
  title        = {Exact solutions to the nonlinear dynamics of learning in deep linear
                  neural networks},
  booktitle    = {International Conference on Learning Representations},
  year         = {2014}
}

@inproceedings{Huang2020,
  author       = {Jiaoyang Huang and
                  Horng-Tzer Yau},
  title        = {Dynamics of Deep Neural Networks and Neural Tangent Hierarchy},
  booktitle    = {International Conference on Machine Learning},
  year         = {2020},
}

@inproceedings{Ji2020,
  author       = {Ziwei Ji and
                  Matus Telgarsky},
  title        = {Directional convergence and alignment in deep learning},
  booktitle    = {Advances in Neural Information Processing Systems},
  year         = {2020},
}

@inproceedings{Kawaguchi2021,
  author       = {Kenji Kawaguchi},
  title        = {On the Theory of Implicit Deep Learning: Global Convergence with Implicit
                  Layers},
  booktitle    = {International Conference on Learning Representations},
  year         = {2021}
}

@inproceedings{Arora2018,
  author       = {Sanjeev Arora and
                  Nadav Cohen and
                  Elad Hazan},
  title        = {On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization},
  booktitle    = {International Conference on Machine Learning},
  year         = {2018}
}


@inproceedings{Arora2019,
  author       = {Sanjeev Arora and
                  Nadav Cohen and
                  Noah Golowich and
                  Wei Hu},
  title        = {A Convergence Analysis of Gradient Descent for Deep Linear Neural
                  Networks},
  booktitle    = {International Conference on Learning Representations},
  year         = {2019},
}

####

@inproceedings{Dauphin2014,
  author       = {Yann N. Dauphin and
                  Razvan Pascanu and
                  Caglar Gulcehre and
                  KyungHyun Cho and
                  Surya Ganguli and
                  Yoshua Bengio},
  title        = {Identifying and attacking the saddle point problem in high-dimensional
                  non-convex optimization},
  booktitle    = {Advances in Neural Information Processing Systems},
  year         = {2014},
}

@inproceedings{Choromanska2015,
  author       = {Anna Choromanska and
                  Mikael Henaff and
                  Michael Mathieu and
                  Gerard Ben Arous and
                  Yann LeCun},
  title        = {The Loss Surfaces of Multilayer Networks},
  booktitle    = {International Conference on Artificial
                  Intelligence and Statistics},
  year         = {2015},
}












@article{Weinan,
  author       = {Weinan E and
                  Chao Ma and
                  Lei Wu},
  title        = {A Comparative Analysis of the Optimization and Generalization Property
                  of Two-layer Neural Network and Random Feature Models Under Gradient
                  Descent Dynamics},
  journal      = {CoRR},
  volume       = {abs/1904.04326},
  year         = {2019},
}

