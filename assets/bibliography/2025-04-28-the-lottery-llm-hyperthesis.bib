@inproceedings{he23solving,
  title={Solving Math Word Problems by Combining Language Models With Symbolic Solvers},
  author={He-Yueya, Joy and Poesia, Gabriel and Wang, Rose and Goodman, Noah},
  booktitle={The 3rd Workshop on Mathematical Reasoning and AI at NeurIPS'23}
}

@inproceedings{NEURIPS2023_d842425e,
 author = {Schick, Timo and Dwivedi-Yu, Jane and Dessi, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {68539--68551},
 publisher = {Curran Associates, Inc.},
 title = {Toolformer: Language Models Can Teach Themselves to Use Tools},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/d842425e4bf79ba039352da0f658a906-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}




@InProceedings{pmlr-v202-gao23f,
  title = 	 {{PAL}: Program-aided Language Models},
  author =       {Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {10764--10799},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/gao23f/gao23f.pdf},
  url = 	 {https://proceedings.mlr.press/v202/gao23f.html},
}



@inproceedings{yao2022react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Shafran, Izhak and Narasimhan, Karthik R and Cao, Yuan},
  booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop}
}


@inproceedings{NEURIPS2023_e3936777,
 author = {Yang, Rui and Song, Lin and Li, Yanwei and Zhao, Sijie and Ge, Yixiao and Li, Xiu and Shan, Ying},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {71995--72007},
 publisher = {Curran Associates, Inc.},
 title = {GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/e393677793767624f2821cec8bdd02f1-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}


@inproceedings{valmeekam2022large,
title={Large Language Models Still Can't Plan (A Benchmark for {LLM}s on Planning and Reasoning about Change)},
author={Karthik Valmeekam and Alberto Olmo and Sarath Sreedharan and Subbarao Kambhampati},
booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop},
year={2022},
url={https://openreview.net/forum?id=wUU-7XTL5XO}
}

@article{xu2023large,
  title={Are large language models really good logical reasoners? a comprehensive evaluation from deductive, inductive and abductive views},
  author={Xu, Fangzhi and Lin, Qika and Han, Jiawei and Zhao, Tianzhe and Liu, Jun and Cambria, Erik},
  journal={arXiv preprint arXiv:2306.09841},
  year={2023}
}

@inproceedings{10.1145/3627673.3679832,
author = {Amirizaniani, Maryam and Martin, Elias and Sivachenko, Maryna and Mashhadi, Afra and Shah, Chirag},
title = {Can LLMs Reason Like Humans? Assessing Theory of Mind Reasoning in LLMs for Open-Ended Questions},
year = {2024},
isbn = {9798400704369},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {34–44},
numpages = {11},
series = {CIKM '24}
}

@misc{arkoudas2023gpt4cantreason,
      title={GPT-4 Can't Reason}, 
      author={Konstantine Arkoudas},
      year={2023},
      eprint={2308.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.03762}, 
}

@inproceedings{merrillexpressive,
  title={The Expressive Power of Transformers with Chain of Thought},
  author={Merrill, William and Sabharwal, Ashish},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@article{JMLRv2220-302,
  author  = {Jorge Perez and Pablo Barcelo and Javier Marinkovic},
  title   = {Attention is Turing-Complete},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {75},
  pages   = {1--35},
  url     = {http://jmlr.org/papers/v22/20-302.html}
}

@inproceedings{deletang2023neural,
title={Neural Networks and the Chomsky Hierarchy},
author={Gregoire Deletang and Anian Ruoss and Jordi Grau-Moya and Tim Genewein and Li Kevin Wenliang and Elliot Catt and Chris Cundy and Marcus Hutter and Shane Legg and Joel Veness and Pedro A Ortega},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=WbxHAzkeQcn}
}

@article{10.1162/tacl_a_00562,
    author = {Merrill, William and Sabharwal, Ashish},
    title = {The Parallelism Tradeoff: Limitations of Log-Precision Transformers},
    journal = {Transactions of the Association for Computational Linguistics},
    year = {2023},
    month = {06},
}
@inproceedings{chiang2023tighter,
  title={Tighter bounds on the expressivity of transformer encoders},
  author={Chiang, David and Cholak, Peter and Pillay, Anand},
  booktitle={International Conference on Machine Learning},
  pages={5544--5562},
  year={2023},
  organization={PMLR}
}

@inproceedings{chakraborty2024transfer,
title={Transfer Q-star : Principled Decoding for {LLM} Alignment},
author={Souradip Chakraborty and Soumya Suvra Ghosal and Ming Yin and Dinesh Manocha and Mengdi Wang and Amrit Bedi and Furong Huang},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=5PrShrKxoX}
}


@inproceedings{fubreak,
  title={Break the Sequential Dependency of LLM Inference Using Lookahead Decoding},
  author={Fu, Yichao and Bailis, Peter and Stoica, Ion and Zhang, Hao},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{brown2024large,
  title={Large language monkeys: Scaling inference compute with repeated sampling},
  author={Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2407.21787},
  year={2024}
}

BibTeX Record
@inproceedings{xie2024travelplanner,
title={TravelPlanner: A Benchmark for Real-World Planning with Language Agents},
author={Jian Xie and Kai Zhang and Jiangjie Chen and Tinghui Zhu and Renze Lou and Yuandong Tian and Yanghua Xiao and Yu Su},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=l5XQzNkAOe}
}


@inproceedings{wangself,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  booktitle={The Eleventh International Conference on Learning Representations}
}


@inproceedings{luoreasoning,
  title={Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning},
  author={LUO, LINHAO and Li, Yuan-Fang and Haf, Reza and Pan, Shirui},
  booktitle={The Twelfth International Conference on Learning Representations}
}


@inproceedings{jiang2023structgpt,
  title={StructGPT: A General Framework for Large Language Model to Reason over Structured Data},
  author={Jiang, Jinhao and Zhou, Kun and Dong, Zican and Ye, Keming and Zhao, Wayne Xin and Wen, Ji-Rong},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={9237--9251},
  year={2023}
}


@inproceedings{zhang2024llm4dyg,
author = {Zhang, Zeyang and Wang, Xin and Zhang, Ziwei and Li, Haoyang and Qin, Yijian and Zhu, Wenwu},
title = {LLM4DyG: Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs?},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4350–4361},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{sunthink,
  title={Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph},
  author={Sun, Jiashuo and Xu, Chengjin and Tang, Lumingyuan and Wang, Saizhuo and Lin, Chen and Gong, Yeyun and Ni, Lionel and Shum, Heung-Yeung and Guo, Jian},
  booktitle={The Twelfth International Conference on Learning Representations}
}


@inproceedings{hong2024metagpt,
title={Meta{GPT}: Meta Programming for A Multi-Agent Collaborative Framework},
author={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Jinlin Wang and Ceyao Zhang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and J{\"u}rgen Schmidhuber},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=VtmBAGCN7o}
}


@article{li2023camel,
  title={Camel: Communicative agents for" mind" exploration of large language model society},
  author={Li, Guohao and Hammoud, Hasan and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={51991--52008},
  year={2023}
}


@article{wangvoyager,
  title={Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={Transactions on Machine Learning Research}
}


@article{liang2023encouraging,
  title={Encouraging divergent thinking in large language models through multi-agent debate},
  author={Liang, Tian and He, Zhiwei and Jiao, Wenxiang and Wang, Xing and Wang, Yan and Wang, Rui and Yang, Yujiu and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2305.19118},
  year={2023}
}

@inproceedings{duimproving,
  title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  booktitle={Forty-first International Conference on Machine Learning}
}



@inproceedings{wu2024autogen,
  title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation},
  author={Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and others},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents}
}


@article{LLM-as-OS,
  title={Llm as os (llmao), agents as apps: Envisioning aios, agents and the aios-agent ecosystem},
  author={Ge, Yingqiang and Ren, Yujie and Hua, Wenyue and Xu, Shuyuan and Tan, Juntao and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2312.03815},
  year={2023}
}


@inproceedings{zhoulanguage,
  title={Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models},
  author={Zhou, Andy and Yan, Kai and Shlapentokh-Rothman, Michal and Wang, Haohan and Wang, Yu-Xiong},
  booktitle={Forty-first International Conference on Machine Learning}
}


@phdthesis{ringer2021proofphd,
  title={Proof Repair (Doctoral dissertation)},
  author={Ringer, Talia},
  year={2021}
}


@inproceedings{ringer2021proof,
author = {Ringer, Talia and Porter, RanDair and Yazdani, Nathaniel and Leo, John and Grossman, Dan},
title = {Proof repair across type equivalences},
year = {2021},
isbn = {9781450383912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
location = {Virtual, Canada},
series = {PLDI 2021}
}



@article{ToT,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{GoT,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}

@article{han2022folio,
  title={Folio: Natural language reasoning with first-order logic},
  author={Han, Simeng and Schoelkopf, Hailey and Zhao, Yilun and Qi, Zhenting and Riddell, Martin and Zhou, Wenfei and Coady, James and Peng, David and Qiao, Yujie and Benson, Luke and others},
  journal={arXiv preprint arXiv:2209.00840},
  year={2022}
}

@article{sunindeterminacy,
  title={From Indeterminacy to Determinacy: Augmenting Logical Reasoning Capabilities with Large Language Models},
  author={Sun, Hongda and Xu, Weikai and Liu, Wei and Luan, Jian and Wang, Bin and Shang, Shuo and Wen, Ji-Rong and Yan, Rui}
}


@inproceedings{sun-etal-2024-determlr,
    title = "{D}eterm{LR}: Augmenting {LLM}-based Logical Reasoning from Indeterminacy to Determinacy",
    author = "Sun, Hongda  and
      Xu, Weikai  and
      Liu, Wei  and
      Luan, Jian  and
      Wang, Bin  and
      Shang, Shuo  and
      Wen, Ji-Rong  and
      Yan, Rui",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    publisher = "Association for Computational Linguistics",
    pages = "9828--9862",
}

@inproceedings{pan-etal-2023-logic,
    title = "Logic-{LM}: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning",
    author = "Pan, Liangming  and
      Albalak, Alon  and
      Wang, Xinyi  and
      Wang, William",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    pages = "3806--3824",
}




@inproceedings{wang2024symbolic,
  title={Symbolic Working Memory Enhances Language Models for Complex Rule Application},
  author={Wang, Siyuan and Wei, Zhongyu and Choi, Yejin and Ren, Xiang},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={17583--17604},
  year={2024}
}


@article{CoT,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}


@inproceedings{Xu2024FaithfulLR,
  title={Faithful Logical Reasoning via Symbolic Chain-of-Thought},
  author={Jundong Xu and Hao Fei and Liangming Pan and Qian Liu and Mong Li Lee and Wynne Hsu},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:270068130}
}


@inproceedings{jaiswal2024compressing,
title={Compressing {LLM}s: The Truth is Rarely Pure and Never Simple},
author={AJAY KUMAR JAISWAL and Zhe Gan and Xianzhi Du and Bowen Zhang and Zhangyang Wang and Yinfei Yang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=B9klVS7Ddk}
}


@inproceedings{tangDVFS,
	author       = {Tang, Zhenheng and Wang, Yuxin and Wang, Qiang and Chu, Xiaowen},
	title        = {The Impact of GPU DVFS on the Energy and Performance of Deep Learning: An Empirical Study},
	year         = {2019},
	isbn         = {9781450366717},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	doi          = {10.1145/3307772.3328315},
	booktitle    = {Proceedings of the Tenth ACM International Conference on Future Energy Systems},
	pages        = {315–325},
	numpages     = {11},
	location     = {Phoenix, AZ, USA},
	series       = {e-Energy '19}
}


@inproceedings{dongpruner,
  title={Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models},
  author={Dong, Peijie and Li, Lujun and Tang, Zhenheng and Liu, Xiang and Pan, Xinglin and Wang, Qiang and Chu, Xiaowen},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{dong2024stbllm,
  title={STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs},
  author={Dong, Peijie and Li, Lujun and Zhong, Yuedong and Du, Dayou and Fan, Ruibo and Chen, Yuhan and Tang, Zhenheng and Wang, Qiang and Xue, Wei and Guo, Yike and others},
  journal={arXiv preprint arXiv:2408.01803},
  year={2024}
}


@inproceedings{samsi2023words,
  title={From words to watts: Benchmarking the energy costs of large language model inference},
  author={Samsi, Siddharth and Zhao, Dan and McDonald, Joseph and Li, Baolin and Michaleas, Adam and Jones, Michael and Bergeron, William and Kepner, Jeremy and Tiwari, Devesh and Gadepally, Vijay},
  booktitle={2023 IEEE High Performance Extreme Computing Conference (HPEC)},
  pages={1--9},
  year={2023},
  organization={IEEE}
}


@inproceedings{10.1145/3620666.3651329,
author = {Patel, Pratyush and Choukse, Esha and Zhang, Chaojie and Goiri, \'{I}\~{n}igo and Warrier, Brijesh and Mahalingam, Nithish and Bianchini, Ricardo},
title = {Characterizing Power Management Opportunities for LLMs in the Cloud},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3620666.3651329},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {207–222},
numpages = {16},
keywords = {large language models, power usage, cloud, datacenters, GPUs, power oversubscription, profiling},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}



@misc{openai2023gpt4,
	title        = {GPT-4 Technical Report},
	author       = {OpenAI},
	year         = {2023},
	eprint       = {2303.08774},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}

@article{touvron2023llama,
	title        = {Llama: Open and efficient foundation language models},
	author       = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
	year         = {2023},
	journal      = {arXiv preprint},
	url          = {https://arxiv.org/abs/2302.13971}
}



@inproceedings{Sun2023ASA_wanda,
	title        = {A Simple and Effective Pruning Approach for Large Language Models},
	author       = {Mingjie Sun and Zhuang Liu and Anna Bair and J. Zico Kolter},
	year         = {2024},
	booktitle    = {International Conference on Learning Representations}
}

@article{Frantar2023SparseGPTML,
	title        = {SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot},
	author       = {Elias Frantar and Dan Alistarh},
	year         = {2023},
	journal      = {ArXiv},
	volume       = {abs/2301.00774}
}

@article{Yao2022ZeroQuantEA,
	title        = {ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers},
	author       = {Zhewei Yao and Reza Yazdani Aminabadi and Minjia Zhang and Xiaoxia Wu and Conglong Li and Yuxiong He},
	year         = {2022},
	journal      = {ArXiv},
	volume       = {abs/2206.01861}
}

@inproceedings{Dettmers2022TheCF,
	title        = {The case for 4-bit precision: k-bit Inference Scaling Laws},
	author       = {Tim Dettmers and Luke Zettlemoyer},
	year         = {2022},
	booktitle    = {International Conference on Machine Learning}
}

@inproceedings{xiao2024efficient,
  author    = {Guangxuan Xiao and Yuandong Tian and Beidi Chen and Song Han and Mike Lewis},
  booktitle = {The Twelfth International Conference on Learning Representations},
  title     = {Efficient Streaming Language Models with Attention Sinks},
  url       = {https://openreview.net/forum?id=NG7sS51zVF},
  year      = {2024}
}


@inproceedings{zhang2024h2o,
  author    = {Zhenyu Zhang and
               Ying Sheng and
               Tianyi Zhou and
               Tianlong Chen and
               Lianmin Zheng and
               Ruisi Cai and
               Zhao Song and
               Yuandong Tian and
               Christopher R{\'{e}} and
               Clark W. Barrett and
               Zhangyang Wang and
               Beidi Chen},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/nips/Zhang00CZC0TRBW23.bib},
  booktitle = {Advances in Neural Information Processing Systems 36: Annual Conference
               on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
               LA, USA, December 10 - 16, 2023},
  editor    = {Alice Oh and
               Tristan Naumann and
               Amir Globerson and
               Kate Saenko and
               Moritz Hardt and
               Sergey Levine},
  timestamp = {Fri, 15 Mar 2024 00:00:00 +0100},
  title     = {{H2O:} Heavy-Hitter Oracle for Efficient Generative Inference of Large
               Language Models},
  url       = {http://papers.nips.cc/paper\_files/paper/2023/hash/6ceefa7b15572587b78ecfcebb2827f8-Abstract-Conference.html},
  year      = {2023}
}

@article{kumar2024scaling,
  title={Scaling Laws for Precision},
  author={Kumar, Tanishq and Ankner, Zachary and Spector, Benjamin F and Bordelon, Blake and Muennighoff, Niklas and Paul, Mansheej and Pehlevan, Cengiz and R{\'e}, Christopher and Raghunathan, Aditi},
  journal={arXiv preprint arXiv:2411.04330},
  year={2024}
}

@inproceedings{yuan-etal-2024-kv,
    title = "{KV} Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches",
    author = "Yuan, Jiayi  and
      Liu, Hongyi  and
      Zhong, Shaochen  and
      Chuang, Yu-Neng  and
      Li, Songchen  and
      Wang, Guanchu  and
      Le, Duy  and
      Jin, Hongye  and
      Chaudhary, Vipin  and
      Xu, Zhaozhuo  and
      Liu, Zirui  and
      Hu, Xia",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = {Miami, Florida, USA},
    publisher = {Association for Computational Linguistics}
}

@article{banerjee2024llms,
  title={Llms will always hallucinate, and we need to live with this},
  author={Banerjee, Sourav and Agarwal, Ayushi and Singla, Saloni},
  journal={arXiv preprint arXiv:2409.05746},
  year={2024}
}

@inproceedings{li-etal-2024-dawn,
    title = "The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models",
    author = "Li, Junyi  and
      Chen, Jie  and
      Ren, Ruiyang  and
      Cheng, Xiaoxue  and
      Zhao, Xin  and
      Nie, Jian-Yun  and
      Wen, Ji-Rong",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.586",
    doi = "10.18653/v1/2024.acl-long.586",
    pages = "10879--10899",
    abstract = "In the era of large language models (LLMs), hallucination (the tendency to generate factually incorrect content) poses great challenges to trustworthy and reliable deployment of LLMs in real-world applications. To tackle the hallucination, three key questions should be well studied: how to detect hallucinations (detection), why do LLMs hallucinate (source), and what can be done to mitigate them (mitigation). To address these challenges, this work presents a systematic empirical study on LLM hallucinations, focused on the three aspects of hallucination detection, source and mitigation. Specially, we construct a new hallucination benchmark HaluEval 2.0, and design a simple yet effective detection method for LLM hallucinations. Furthermore, we zoom into the different training or utilization stages of LLMs and extensively analyze the potential factors that lead to the LLM hallucinations. Finally, we implement and examine a series of widely used techniques to mitigate the hallucinations in LLMs. Our work has led to several important findings to understand the hallucination origin and mitigate the hallucinations in LLMs.",
}

@article{xu2024hallucination,
  title={Hallucination is inevitable: An innate limitation of large language models},
  author={Xu, Ziwei and Jain, Sanjay and Kankanhalli, Mohan},
  journal={arXiv preprint arXiv:2401.11817},
  year={2024}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={ACM Transactions on Information Systems},
  year={2023},
  publisher={ACM New York, NY}
}


@article{farquhar2024detecting,
  title={Detecting hallucinations in large language models using semantic entropy},
  author={Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
  journal={Nature},
  volume={630},
  number={8017},
  pages={625--630},
  year={2024}
}


@inproceedings{jeong2024adaptive,
  title={Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity},
  author={Jeong, Soyeong and Baek, Jinheon and Cho, Sukmin and Hwang, Sung Ju and Park, Jong C},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={7029--7043},
  year={2024}
}

@article{soudani2024fine,
  title={Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge},
  author={Soudani, Heydar and Kanoulas, Evangelos and Hasibi, Faegheh},
  journal={arXiv preprint arXiv:2403.01432},
  year={2024}
}

@article{moffat2019huffman,
author = {Moffat, Alistair},
title = {Huffman Coding},
year = {2019},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3342555},
doi = {10.1145/3342555},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {85},
numpages = {35},
}

@inproceedings{hendrycks2021measuring,
title={Measuring Massive Multitask Language Understanding},
author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=d7KBjmI3GmQ}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@inproceedings{wilkins2024hybrid,
  title={Hybrid Heterogeneous Clusters Can Lower the Energy Consumption of LLM Inference Workloads},
  author={Wilkins, Grant and Keshav, Srinivasan and Mortier, Richard},
  booktitle={Proceedings of the 15th ACM International Conference on Future and Sustainable Energy Systems},
  pages={506--513},
  year={2024}
}

@article{pipitone2024legalbench,
  title={LegalBench-RAG: A Benchmark for Retrieval-Augmented Generation in the Legal Domain},
  author={Pipitone, Nicholas and Alami, Ghita Houir},
  journal={arXiv preprint arXiv:2408.10343},
  year={2024}
}

@article{gao2023retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  year={2023}
}


@article{jeong2024improving,
  title={Improving medical reasoning through retrieval and self-reflection with retrieval-augmented large language models},
  author={Jeong, Minbyul and Sohn, Jiwoong and Sung, Mujeen and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={40},
  number={Supplement\_1},
  pages={i119--i129},
  year={2024},
  publisher={Oxford University Press}
}

@inproceedings{chen-etal-2024-retrieval,
    title = "Retrieval-Augmented Knowledge Integration into Language Models: A Survey",
    author = {Chen, Yuxuan  and
      R{\"o}der, Daniel  and
      Erker, Justus-Jonas  and
      Hennig, Leonhard  and
      Thomas, Philippe  and
      M{\"o}ller, Sebastian  and
      Roller, Roland},
    editor = "Li, Sha  and
      Li, Manling  and
      Zhang, Michael JQ  and
      Choi, Eunsol  and
      Geva, Mor  and
      Hase, Peter  and
      Ji, Heng",
    booktitle = "Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "45--63",
}

@inproceedings{li-etal-2024-alphafin,
    title = "{A}lpha{F}in: Benchmarking Financial Analysis with Retrieval-Augmented Stock-Chain Framework",
    author = "Li, Xiang  and
      Li, Zhenyu  and
      Shi, Chen  and
      Xu, Yong  and
      Du, Qing  and
      Tan, Mingkui  and
      Huang, Jun",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    publisher = "ELRA and ICCL",
    pages = "773--783",
}



@inproceedings{talmor-etal-2019-commonsenseqa,
    title = "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge",
    author = "Talmor, Alon  and
      Herzig, Jonathan  and
      Lourie, Nicholas  and
      Berant, Jonathan",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1421",
    doi = "10.18653/v1/N19-1421",
    pages = "4149--4158",
}


@article{merity2016pointer,
	title        = {Pointer Sentinel Mixture Models},
	author       = {Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
	year         = 2016,
	booktitle    = {ICLR},
	url          = {https://openreview.net/forum?id=Byj72udxe}
}


@article{raffel2020exploring,
	title        = {Exploring the limits of transfer learning with a unified text-to-text transformer},
	author       = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
	year         = 2020,
	journal      = {JMLR},
	publisher    = {JMLRORG},
	url          = {https://dl.acm.org/doi/abs/10.5555/3455716.3455856}
}

@article{marcus1993building,
	title        = {Building a Large Annotated Corpus of English: The Penn Treebank},
	author       = {Marcus, Mitch and Santorini, Beatrice and Marcinkiewicz, Mary Ann},
	year         = 1993,
	journal      = {Computational Linguistics},
	url          = {https://aclanthology.org/J93-2004.pdf}
}



@misc{choi2024automatic,
  author       = {Choi, Dami and Huang, Vincent and Meng, Kevin and Johnson, Daniel D and Steinhardt, Jacob and Schwettmann, Sarah},
  title        = {Scaling Automatic Neuron Description},
  year         = {2024},
  month        = {October},
  day          = {23},
  howpublished = {\url{https://transluce.org/neuron-descriptions}}
}

@inproceedings{Granite-Function,
  title={Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks},
  author={Ibrahim Abdelaziz and Kinjal Basu and Mayank Agarwal and Sadhana Kumaravel and Matt Stallone and Rameswar Panda and Yara Rizk and G. Bhargav and M. Crouse and Chulaka Gunasekara and S. Ikbal and Sachin Joshi and Hima P. Karanam and Vineet Kumar and Asim Munawar and S. Neelam and Dinesh Raghu and Udit Sharma and Adriana Meza Soria and Dheeraj Sreedhar and P. Venkateswaran and Merve Unuvar and David Cox and S. Roukos and Luis A. Lastras and P. Kapanipathi},
  year={2024},
  url={https://www.semanticscholar.org/paper/cbde6f07977255cd5b571d93b497aa2874a7a544},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
}


@inproceedings{FreshLLMs,
    title={FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation},
    author={Tu Vu and Mohit Iyyer and Xuezhi Wang and Noah Constant and Jerry Wei and Jason Wei and Chris Tar and Yun-Hsuan Sung and Denny Zhou and Quoc Le and Thang Luong},
    year={2023},
    url={https://www.semanticscholar.org/paper/be177300487b6d0f25e6cade9a31900454b13281},
    booktitle={Annual Meeting of the Association for Computational Linguistics},
}


@article{AIOS,
    title={AIOS: LLM Agent Operating System},
    author={Kai Mei and Zelong Li and Shuyuan Xu and Ruosong Ye and Yingqiang Ge and Yongfeng Zhang},
    year={2024},
    url={https://www.semanticscholar.org/paper/f89e85059a55b647c93822aefa7e985376e0ef20},
    journal={arXiv.org},
}



@article{LLM-as-OS,
    title={LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem},
    author={Yingqiang Ge and Yujie Ren and Wenyue Hua and Shuyuan Xu and Juntao Tan and Yongfeng Zhang},
    year={2023},
    url={https://www.semanticscholar.org/paper/f4e8e66557005af41e101caf9d16d63bf7fe6f9a},
    journal={arXiv.org},
}



@article{ToolLLM,
    title={ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs},
    author={Yujia Qin and Shi Liang and Yining Ye and Kunlun Zhu and Lan Yan and Ya-Ting Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Runchu Tian and Ruobing Xie and Jie Zhou and M. Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
    year={2023},
    url={https://www.semanticscholar.org/paper/0bfc804e31eecfd77f45e4ee7f4d629fffdcd628},
    journal={International Conference on Learning Representations},
}

@inproceedings{PopQA,
    title = "When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories",
    author = "Mallen, Alex  and
      Asai, Akari  and
      Zhong, Victor  and
      Das, Rajarshi  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    pages = "9802--9822",
}



@article{GSM-Symbolic,
    title={GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models},
    author={Iman Mirzadeh and Keivan Alizadeh-Vahid and Hooman Shahrokhi and Oncel Tuzel and Samy Bengio and Mehrdad Farajtabar},
    year={2024},
    url={https://www.semanticscholar.org/paper/05506581cade1a8ef6372616cec20b81a3d5c366},
    journal={arXiv.org},
}


@article{Grokking,
    title={Progress measures for grokking via mechanistic interpretability},
    author={Neel Nanda and Lawrence Chan and Tom Lieberum and Jess Smith and J. Steinhardt},
    year={2023},
    url={https://www.semanticscholar.org/paper/f680d47a51a0e470fcb228bf0110c026535ead1b},
    journal={International Conference on Learning Representations},
}



@article{Reveal-CoT,
    title={Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective},
    author={Guhao Feng and Yuntian Gu and Bohang Zhang and Haotian Ye and Di He and Liwei Wang},
    year={2023},
    url={https://www.semanticscholar.org/paper/c2260403fd5cb2de73491323433e48b6ec36872c},
    journal={Neural Information Processing Systems},
}


@article{CanLLMReason,
    title={Can large language models reason and plan?},
    author={Subbarao Kambhampati},
    year={2024},
    url={https://www.semanticscholar.org/paper/f531d1a681ed12fd582767133318d0728316a0ae},
    journal={Annals of the New York Academy of Sciences},
}


@article{Memory-Augmented-Turing,
    title={Memory Augmented Large Language Models are Computationally Universal},
    author={Dale Schuurmans},
    year={2023},
    url={https://www.semanticscholar.org/paper/7ec58d26c4dddb4bc3b6829fa0654a22cc26fdfe},
    journal={arXiv.org},
}
@article{Autogressive-Turing,
    title={Autoregressive Large Language Models are Computationally Universal},
    author={Dale Schuurmans and Hanjun Dai and Francesco Zanini},
    year={2024},
    url={https://www.semanticscholar.org/paper/b72b981bd59ffb1536c7a9e92e43b882f36d3e5c},
    journal={arXiv.org},
}


@article{RecursiveReasoning,
    title={Can Transformers Learn to Solve Problems Recursively?},
    author={Shizhuo Zhang and Curt Tigges and Stella Biderman and M. Raginsky and T. Ringer},
    year={2023},
    url={https://www.semanticscholar.org/paper/45c196d28d16b2a8c0a078e8b79bcb39887a8a9f},
    journal={arXiv.org},
}




@inproceedings{Decoding,
    title={Machine Translation Decoding beyond Beam Search},
    author={Rémi Leblond and Jean-Baptiste Alayrac and L. Sifre and Miruna Pislar and Jean-Baptiste Lespiau and Ioannis Antonoglou and K. Simonyan and O. Vinyals},
    year={2021},
    url={https://www.semanticscholar.org/paper/e8cc5b6204970a88cd1b2df491aa10c4333e083e},
    booktitle={Conference on Empirical Methods in Natural Language Processing},
}

@article{Stack-Attention,
    title={A Transformer with Stack Attention},
    author={Jiaoda Li and Jennifer C. White and Mrinmaya Sachan and Ryan Cotterell},
    year={2024},
    url={https://www.semanticscholar.org/paper/5d7946b41dea3ed11dad48a53b1390d59b8c564e},
    journal={NAACL-HLT},
}


@article{needle,
  author  = {Gregory Kamradt},
  journal = {Github},
  title   = {{Needle In A Haystack} - Pressure Testing {LLM}s},
  url     = {https://github.com/gkamradt/LLMTest_NeedleInAHaystack/tree/main},
  year    = {2023}
}


@inproceedings{mallen2023not,
  title={When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories},
  author={Mallen, Alex and Asai, Akari and Zhong, Victor and Das, Rajarshi and Khashabi, Daniel and Hajishirzi, Hannaneh},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9802--9822},
  year={2023}
}
@article{kwiatkowski2019natural,
  title={Natural questions: a benchmark for question answering research},
  author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={453--466},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{stelmakh2022asqa,
  title={ASQA: Factoid Questions Meet Long-Form Answers},
  author={Stelmakh, Ivan and Luan, Yi and Dhingra, Bhuwan and Chang, Ming-Wei},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={8273--8288},
  year={2022}
}



@inproceedings{asai2024selfrag,
title={Self-{RAG}: Learning to Retrieve, Generate, and Critique through Self-Reflection},
author={Akari Asai and Zeqiu Wu and Yizhong Wang and Avirup Sil and Hannaneh Hajishirzi},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=hSyW5go0v8}
}






@article{pan2024survey,
author = {Pan, James Jie and Wang, Jianguo and Li, Guoliang},
title = {Survey of vector database management systems},
year = {2024},
issue_date = {Sep 2024},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {5},
issn = {1066-8888},
url = {https://doi.org/10.1007/s00778-024-00864-x},
journal = {The VLDB Journal},
month = jul,
pages = {1591–1615},
numpages = {25},
}


























