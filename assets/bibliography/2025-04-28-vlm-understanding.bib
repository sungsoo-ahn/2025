@article{palit2023towards,
  title     = {Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP},
  author    = {Vedant Palit and Rohan Pandey and Aryaman Arora and P. Liang},
  journal   = {IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)},
  year      = {2023},
  doi       = {10.1109/ICCVW60793.2023.00307},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/d494727306a375e524c4c4c8cc1a2dc1845cc4b7}
}

@article{golovanevsky2024vlms,
  title   = {What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Gaussian-Noise-free Text-Image Corruption and Evaluation},
  author  = {Michal Golovanevsky and William Rudman and Vedant Palit and Ritambhara Singh and Carsten Eickhoff},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2406.16320},
  url     = {https://arxiv.org/abs/2406.16320v2},
  pdf     = {https://arxiv.org/pdf/2406.16320.pdf}
}

@article{weng2024images,
  title   = {Images Speak Louder than Words: Understanding and Mitigating Bias in Vision-Language Model from a Causal Mediation Perspective},
  author  = {Zhaotian Weng and Zijun Gao and Jerone Andrews and Jieyu Zhao},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2407.02814}
}

@incollection{DBLP:books/acm/22/Pearl22l,
  author    = {Judea Pearl},
  editor    = {Hector Geffner and Rina Dechter and Joseph Y. Halpern},
  title     = {Direct and Indirect Effects},
  booktitle = {Probabilistic and Causal Inference: The Works of Judea Pearl},
  series    = {{ACM} Books},
  volume    = {36},
  pages     = {373-392},
  publisher = {ACM},
  year      = {2022},
  url       = {https://doi.org/10.1145/3501714.3501736},
  doi       = {10.1145/3501714.3501736},
  timestamp = {Thu, 21 Sep 2023 16:27:52 +0200},
  biburl    = {https://dblp.org/rec/books/acm/22/Pearl22l.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  pdf       = {https://arxiv.org/pdf/1301.2300.pdf}
}

@inproceedings{NEURIPS2020_92650b2e,
  author    = {Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Singer, Yaron and Shieber, Stuart},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages     = {12388-12401},
  publisher = {Curran Associates, Inc.},
  title     = {Investigating Gender Bias in Language Models Using Causal Mediation Analysis},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2020/file/92650b2e92217715fe312e6fa7b90d82-Paper.pdf},
  volume    = {33},
  year      = {2020},
  pdf       = {https://proceedings.neurips.cc/paper/2020/file/92650b2e92217715fe312e6fa7b90d82-Paper.pdf}
}

@article{zhang2023towards,
  title     = {Towards Best Practices of Activation Patching in Language Models: Metrics and Methods},
  author    = {Fred Zhang and Neel Nanda},
  journal   = {International Conference on Learning Representations},
  year      = {2023},
  doi       = {10.48550/arXiv.2309.16042},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/c16c05ca0a3d24519405849fd24604fc1ce47751},
  url       = {https://arxiv.org/abs/2309.16042v2},
  pdf       = {https://arxiv.org/pdf/2309.16042.pdf}
}

@inproceedings{NEURIPS2022_6f1d43d5,
  author    = {Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {17359-17372},
  publisher = {Curran Associates, Inc.},
  title     = {Locating and Editing Factual Associations in GPT},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/6f1d43d5a82a37e89b0665b33bf3a182-Paper-Conference.pdf},
  volume    = {35},
  year      = {2022},
  pdf       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/6f1d43d5a82a37e89b0665b33bf3a182-Abstract-Conference.html}
}

@article{olsson2022incontext,
  title   = {In-context Learning and Induction Heads},
  author  = {Catherine Olsson and Nelson Elhage and Neel Nanda and Nicholas Joseph and Nova DasSarma and Tom Henighan and Ben Mann and Amanda Askell and Yuntao Bai and Anna Chen and Tom Conerly and Dawn Drain and Deep Ganguli and Zac Hatfield-Dodds and Danny Hernandez and Scott Johnston and Andy Jones and Jackson Kernion and Liane Lovitt and Kamal Ndousse and Dario Amodei and Tom Brown and Jack Clark and Jared Kaplan and Sam McCandlish and Chris Olah},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2209.11895},
  url     = {https://arxiv.org/abs/2209.11895v1},
  pdf     = {https://arxiv.org/pdf/2209.11895.pdf}
}

@inproceedings{DBLP:conf/iclr/WangVCSS23,
  author    = {Kevin Ro Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt},
  title     = {Interpretability in the Wild: a Circuit for Indirect Object Identification in {GPT-2} Small},
  booktitle = {The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher = {OpenReview.net},
  year      = {2023},
  url       = {https://openreview.net/forum?id=NpsVSN6o4ul},
  timestamp = {Wed, 24 Jul 2024 16:50:33 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/WangVCSS23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  pdf       = {https://arxiv.org/pdf/2211.00593.pdf}
}

@inproceedings{NEURIPS2023_efbba771,
  author    = {Hanna, Michael and Liu, Ollie and Variengien, Alexandre},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
  pages     = {76033-76060},
  publisher = {Curran Associates, Inc.},
  title     = {How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2023/file/efbba7719cc5172d175240f24be11280-Paper-Conference.pdf},
  volume    = {36},
  year      = {2023},
  pdf       = {https://proceedings.neurips.cc/paper_files/paper/2023/file/efbba7719cc5172d175240f24be11280-Abstract-Conference.html}
}

@article{bereska2024mechanistic,
  title   = {Mechanistic Interpretability for AI Safety - A Review},
  author  = {Leonard Bereska and Efstratios Gavves},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2404.14082},
  url     = {https://arxiv.org/abs/2404.14082v3},
  pdf     = {https://arxiv.org/pdf/2404.14082.pdf}
}

@misc{alignmentforumorg2024interpreting,
  author = {Alignmentforum.org},
  title  = {interpreting GPT: the logit lens — AI Alignment Forum},
  year   = {2024},
  url    = {https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens},
  note   = {Accessed 2024-11-04},
  pdf    = {https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens}
}

@article{tang2024languagespecific,
  title     = {Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models},
  author    = {Tianyi Tang and Wenyang Luo and Haoyang Huang and Dongdong Zhang and Xiaolei Wang and Xin Zhao and Furu Wei and Ji-Rong Wen},
  journal   = {Annual Meeting of the Association for Computational Linguistics},
  year      = {2024},
  doi       = {10.48550/arXiv.2402.16438},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/96edfa3441bb3624ea2b8bdfc5eec2c87efa9637},
  url       = {https://arxiv.org/abs/2402.16438v2},
  pdf       = {https://arxiv.org/pdf/2402.16438.pdf}
}

@article{huo2024mmneuron,
  title   = {MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model},
  author  = {Jiahao Huo and Yibo Yan and Boren Hu and Yutao Yue and Xuming Hu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2406.11193}
}

@article{huang2024miner,
  title   = {MINER: Mining the Underlying Pattern of Modality-Specific Neurons in Multimodal Large Language Models},
  author  = {Kaichen Huang and Jiahao Huo and Yibo Yan and Kun Wang and Yutao Yue and Xuming Hu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.04819}
}

@article{neo2024towards,
  title   = {Towards Interpreting Visual Information Processing in Vision-Language Models},
  author  = {Clement Neo and Luke Ong and Philip Torr and Mor Geva and David Krueger and Fazl Barez},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.07149},
  url     = {https://arxiv.org/abs/2410.07149v1},
  pdf     = {https://arxiv.org/pdf/2410.07149.pdf}
}

@article{gandelsman2023interpreting,
  title     = {Interpreting CLIP's Image Representation via Text-Based Decomposition},
  author    = {Yossi Gandelsman and Alexei A. Efros and Jacob Steinhardt},
  journal   = {International Conference on Learning Representations},
  year      = {2023},
  doi       = {10.48550/arXiv.2310.05916},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/48da5f9e5e8953f3c0d5855e2cd033541fc898c1},
  url       = {https://arxiv.org/abs/2310.05916v4},
  pdf       = {https://arxiv.org/pdf/2310.05916.pdf}
}

@article{gandelsman2024interpreting,
  title   = {Interpreting the Second-Order Effects of Neurons in CLIP},
  author  = {Yossi Gandelsman and Alexei A. Efros and Jacob Steinhardt},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2406.04341},
  url     = {https://arxiv.org/abs/2406.04341v2},
  pdf     = {https://arxiv.org/pdf/2406.04341.pdf}
}

@article{balasubramanian2024decomposing,
  title   = {Decomposing and Interpreting Image Representations via Text in ViTs Beyond CLIP},
  author  = {Sriram Balasubramanian and Samyadeep Basu and Soheil Feizi},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2406.01583},
  url     = {https://arxiv.org/abs/2406.01583v2},
  pdf     = {https://arxiv.org/pdf/2406.01583.pdf}
}

@article{jiang2024interpreting,
  title   = {Interpreting and Editing Vision-Language Representations to Mitigate Hallucinations},
  author  = {Nick Jiang and Anish Kachinthaya and Suzie Petryk and Yossi Gandelsman},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.02762},
  url     = {https://arxiv.org/abs/2410.02762v1},
  pdf     = {https://arxiv.org/pdf/2410.02762.pdf}
}

@inproceedings{DBLP:conf/icml/ShahamSWRHA024,
  author    = {Tamar Rott Shaham and Sarah Schwettmann and Franklin Wang and Achyuta Rajaram and Evan Hernandez and Jacob Andreas and Antonio Torralba},
  title     = {A Multimodal Automated Interpretability Agent},
  booktitle = {Forty-first International Conference on Machine Learning, {ICML} 2024, Vienna, Austria, July 21-27, 2024},
  publisher = {OpenReview.net},
  year      = {2024},
  url       = {https://openreview.net/forum?id=mDw42ZanmE},
  timestamp = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/ShahamSWRHA024.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  pdf       = {https://arxiv.org/pdf/2404.14394.pdf}
}

@article{joshi2021review,
  title     = {A review on explainability in multimodal deep neural nets},
  author    = {Joshi, Gargi and Walambe, Rahee and Kotecha, Ketan},
  journal   = {IEEE Access},
  volume    = {9},
  pages     = {59800-59821},
  year      = {2021},
  publisher = {IEEE}
}

@misc{Joseph2024,
  author = {Joseph, Sonia},
  title = {Multimodal interpretability in 2024},
  year = {2024},
  howpublished = {\url{https://www.soniajoseph.ai/multimodal-interpretability-in-2024/}},
}

@inproceedings{Palit_2023_ICCV,
  author    = {Palit, Vedant and Pandey, Rohan and Arora, Aryaman and Liang, Paul Pu},
  title     = {Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},
  month     = {October},
  year      = {2023},
  pages     = {2856-2861},
  url       = {https://openaccess.thecvf.com/content/ICCV2023W/CLVL/html/Palit_Towards_Vision-Language_Mechanistic_Interpretability_A_Causal_Tracing_Tool_for_BLIP_ICCVW_2023_paper.html},
  pdf       = {https://openaccess.thecvf.com/content/ICCV2023W/CLVL/papers/Palit_Towards_Vision-Language_Mechanistic_Interpretability_A_Causal_Tracing_Tool_for_BLIP_ICCVW_2023_paper.pdf}
}

@inproceedings{Ben_Melech_Stan_2024_CVPR,
  author    = {Ben Melech Stan, Gabriela and Aflalo, Estelle and Rohekar, Raanan Yehezkel and Bhiwandiwalla, Anahita and Tseng, Shao-Yen and Olson, Matthew Lyle and Gurwicz, Yaniv and Wu, Chenfei and Duan, Nan and Lal, Vasudev},
  title     = {LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  month     = {June},
  year      = {2024},
  pages     = {8182-8187},
  url       = {https://openaccess.thecvf.com/content/CVPR2024W/XAI4CV/html/Stan_LVLM-Intrepret_An_Interpretability_Tool_for_Large_Vision-Language_Models_CVPRW_2024_paper.html},
  pdf       = {https://openaccess.thecvf.com/content/CVPR2024W/XAI4CV/papers/Stan_LVLM-Intrepret_An_Interpretability_Tool_for_Large_Vision-Language_Models_CVPRW_2024_paper.pdf}
}

@article{geva2023dissecting,
  title   = {Dissecting Recall of Factual Associations in Auto-Regressive Language Models},
  author  = {Mor Geva and Jasmijn Bastings and Katja Filippova and Amir Globerson},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2304.14767},
  url     = {https://arxiv.org/abs/2304.14767v3},
  pdf     = {https://arxiv.org/pdf/2304.14767.pdf}
}

@article{teneggi2024bet,
  title   = {I Bet You Did Not Mean That: Testing Semantic Importance via Betting},
  author  = {Jacopo Teneggi and Jeremias Sulam},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2405.19146},
  url     = {https://arxiv.org/abs/2405.19146v2},
  pdf     = {https://arxiv.org/pdf/2405.19146.pdf}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature machine intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{wang2024towards,
  title   = {Towards Universality: Studying Mechanistic Similarity Across Language Model Architectures},
  author  = {Junxuan Wang and Xuyang Ge and Wentao Shu and Qiong Tang and Yunhua Zhou and Zhengfu He and Xipeng Qiu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.06672},
  url     = {https://arxiv.org/abs/2410.06672v2},
  pdf     = {https://arxiv.org/pdf/2410.06672.pdf}
}

@article{he2024llama,
  title   = {Llama Scope: Extracting Millions of Features from Llama-3.1-8B with Sparse Autoencoders},
  author  = {Zhengfu He and Wentao Shu and Xuyang Ge and Lingjie Chen and Junxuan Wang and Yunhua Zhou and Frances Liu and Qipeng Guo and Xuanjing Huang and Zuxuan Wu and Yu-Gang Jiang and Xipeng Qiu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.20526},
  url     = {https://arxiv.org/abs/2410.20526v1},
  pdf     = {https://arxiv.org/pdf/2410.20526.pdf}
}

@article{koh2020concept,
  title     = {Concept Bottleneck Models},
  author    = {Pang Wei Koh and Thao Nguyen and Y. S. Tang and Stephen Mussmann and E. Pierson and Been Kim and Percy Liang},
  journal   = {International Conference on Machine Learning},
  year      = {2020},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/3a24bfb77ed271fef948058e414850f89b0955a7},
  url       = {https://arxiv.org/abs/2007.04612v3},
  pdf       = {https://arxiv.org/pdf/2007.04612.pdf}
}

@article{bricken2023monosemanticity,
       title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
       author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
       year={2023},
       journal={Transformer Circuits Thread},
       note={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
    }

@article{elhage2022toy,
  title   = {Toy Models of Superposition},
  author  = {Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2209.10652},
  url     = {https://arxiv.org/abs/2209.10652v1},
  pdf     = {https://arxiv.org/pdf/2209.10652.pdf}
}

@inproceedings{DBLP:conf/eccv/RaoMBS24,
  author    = {Sukrut Rao and Sweta Mahajan and Moritz B{\"{o}}hle and Bernt Schiele},
  editor    = {Ales Leonardis and Elisa Ricci and Stefan Roth and Olga Russakovsky and Torsten Sattler and G{\"{u}}l Varol},
  title     = {Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery},
  booktitle = {Computer Vision - {ECCV} 2024 - 18th European Conference, Milan, Italy, September 29-October 4, 2024, Proceedings, Part {LXXVII}},
  series    = {Lecture Notes in Computer Science},
  volume    = {15135},
  pages     = {444-461},
  publisher = {Springer},
  year      = {2024},
  url       = {https://doi.org/10.1007/978-3-031-72980-5\_26},
  doi       = {10.1007/978-3-031-72980-5\_26},
  timestamp = {Fri, 08 Nov 2024 20:51:06 +0100},
  biburl    = {https://dblp.org/rec/conf/eccv/RaoMBS24.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{hugo2024towards,
  author = {Fry Hugo},
  title  = {Towards Multimodal Interpretability: Learning Sparse Interpretable Features in Vision Transformers — LessWrong},
  year   = {2024},
  url    = {https://www.lesswrong.com/posts/bCtbuWraqYTDtuARg/towards-multimodal-interpretability-learning-sparse-2},
  note   = {Accessed 2024-11-18},
  pdf    = {https://www.lesswrong.com/posts/bCtbuWraqYTDtuARg/towards-multimodal-interpretability-learning-sparse-2}
}

@misc{oikarinenLabelfreeConceptBottleneck2023,
  title = {Label-Free Concept Bottleneck Models},
  author = {Oikarinen, Tuomas and Das, Subhro and Nguyen, Lam M. and Weng, Tsui-Wei},
  year = {2023},
  month = jun,
  number = {arXiv:2304.06129},
  eprint = {2304.06129},
  publisher = {arXiv},
  urldate = {2024-11-18},
  abstract = {Concept bottleneck models (CBM) are a popular way of creating more interpretable neural networks by having hidden layer neurons correspond to human-understandable concepts. However, existing CBMs and their variants have two crucial limitations: first, they need to collect labeled data for each of the predefined concepts, which is time consuming and labor intensive; second, the accuracy of a CBM is often significantly lower than that of a standard neural network, especially on more complex datasets. This poor performance creates a barrier for adopting CBMs in practical real world applications. Motivated by these challenges, we propose Label-free CBM which is a novel framework to transform any neural network into an interpretable CBM without labeled concept data, while retaining a high accuracy. Our Label-free CBM has many advantages, it is: scalable - we present the first CBM scaled to ImageNet, efficient - creating a CBM takes only a few hours even for very large datasets, and automated - training it for a new dataset requires minimal human effort. Our code is available at https://github.com/Trustworthy-ML-Lab/Label-free-CBM. Finally, in Appendix B we conduct a large scale user evaluation of the interpretability of our method.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {/unread,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/leonardo/Zotero/storage/6HXZ2M9D/Oikarinen 等 - 2023 - Label-free concept bottleneck models.pdf}
}

@misc{raoDiscoverthennameTaskagnosticConcept2024,
  title = {Discover-Then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery},
  shorttitle = {Discover-Then-Name},
  author = {Rao, Sukrut and Mahajan, Sweta and B{\"o}hle, Moritz and Schiele, Bernt},
  year = {2024},
  month = aug,
  number = {arXiv:2407.14499},
  eprint = {2407.14499},
  publisher = {arXiv},
  urldate = {2024-11-16},
  abstract = {Concept Bottleneck Models (CBMs) have recently been proposed to address the 'black-box' problem of deep neural networks, by first mapping images to a human-understandable concept space and then linearly combining concepts for classification. Such models typically require first coming up with a set of concepts relevant to the task and then aligning the representations of a feature extractor to map to these concepts. However, even with powerful foundational feature extractors like CLIP, there are no guarantees that the specified concepts are detectable. In this work, we leverage recent advances in mechanistic interpretability and propose a novel CBM approach -- called Discover-then-Name-CBM (DN-CBM) -- that inverts the typical paradigm: instead of pre-selecting concepts based on the downstream classification task, we use sparse autoencoders to first discover concepts learnt by the model, and then name them and train linear probes for classification. Our concept extraction strategy is efficient, since it is agnostic to the downstream task, and uses concepts already known to the model. We perform a comprehensive evaluation across multiple datasets and CLIP architectures and show that our method yields semantically meaningful concepts, assigns appropriate names to them that make them easy to interpret, and yields performant and interpretable CBMs. Code available at https://github.com/neuroexplicit-saar/discover-then-name.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {/done,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,interpretability/methods/C-XAI},
  file = {/Users/leonardo/Zotero/storage/9IQBLERM/Rao 等 - 2024 - Discover-then-name task-agnostic concept bottlenecks via automated concept discovery.pdf}
}


@article{zhang2024visuallygrounded,
  title   = {Why are Visually-Grounded Language Models Bad at Image Classification?},
  author  = {Yuhui Zhang and Alyssa Unell and Xiaohan Wang and Dhruba Ghosh and Yuchang Su and Ludwig Schmidt and Serena Yeung-Levy},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2405.18415},
  url     = {https://arxiv.org/abs/2405.18415v2},
  pdf     = {https://arxiv.org/pdf/2405.18415.pdf}
}

@misc{kantamneni2024sae,
  author = {Subhash Kantamneni and JoshEngels and Senthooran Rajamanoharan and Neel Nanda},
  title  = {SAE Probing: What is it good for? Absolutely something! — LessWrong},
  year   = {2024},
  url    = {https://www.lesswrong.com/posts/NMLq8yoTecAF44KX9/sae-probing-what-is-it-good-for-absolutely-something},
  note   = {Accessed 2024-11-19},
  pdf    = {https://www.lesswrong.com/posts/NMLq8yoTecAF44KX9/sae-probing-what-is-it-good-for-absolutely-something}
}

@misc{bricken2024using,
  author = {Trenton Bricken and Jonathan Marcus and Siddharth Mishra-Sharma and Meg Tong and Ethan Perez and Mrinank Sharma and Kelley Rivoire and Thomas Henighan; edited by Adam Jermyn},
  title  = {Using Dictionary Learning Features as Classifiers},
  year   = {2024},
  url    = {https://transformer-circuits.pub/2024/features-as-classifiers/index.html},
  note   = {Accessed 2024-11-19},
  pdf    = {https://transformer-circuits.pub/2024/features-as-classifiers/index.html}
}

@article{cao2020behind,
  title     = {Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models},
  author    = {Jize Cao and Zhe Gan and Yu Cheng and Licheng Yu and Yen-Chun Chen and Jingjing Liu},
  journal   = {European Conference on Computer Vision},
  year      = {2020},
  doi       = {10.1007/978-3-030-58539-6_34},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/3b0d38302115af1165639d6fb34c4c19187b2a6f},
  url       = {https://arxiv.org/abs/2005.07310v2},
  pdf       = {https://arxiv.org/pdf/2005.07310.pdf}
}

@inproceedings{dahlgren-lindstrom-etal-2020-probing,
  title     = {Probing Multimodal Embeddings for Linguistic Properties: the Visual-Semantic Case},
  author    = {Dahlgren Lindstr{\"o}m, Adam and Bj{\"o}rklund, Johanna and Bensch, Suna and Drewes, Frank},
  editor    = {Scott, Donia and Bel, Nuria and Zong, Chengqing},
  booktitle = {Proceedings of the 28th International Conference on Computational Linguistics},
  month     = {dec},
  year      = {2020},
  address   = {Barcelona, Spain (Online)},
  publisher = {International Committee on Computational Linguistics},
  url       = {https://aclanthology.org/2020.coling-main.64},
  doi       = {10.18653/v1/2020.coling-main.64},
  pages     = {730-744},
  abstract  = {Semantic embeddings have advanced the state of the art for countless natural language processing tasks, and various extensions to multimodal domains, such as visual-semantic embeddings, have been proposed. While the power of visual-semantic embeddings comes from the distillation and enrichment of information through machine learning, their inner workings are poorly understood and there is a shortage of analysis tools. To address this problem, we generalize the notion ofprobing tasks to the visual-semantic case. To this end, we (i) discuss the formalization of probing tasks for embeddings of image-caption pairs, (ii) define three concrete probing tasks within our general framework, (iii) train classifiers to probe for those properties, and (iv) compare various state-of-the-art embeddings under the lens of the proposed probing tasks. Our experiments reveal an up to 16{\%} increase in accuracy on visual-semantic embeddings compared to the corresponding unimodal embeddings, which suggest that the text and image dimensions represented in the former do complement each other.},
  pdf       = {https://aclanthology.org/2020.coling-main.64.pdf}
}

@article{hendricks2021probing,
  title     = {Probing Image-Language Transformers for Verb Understanding},
  author    = {Lisa Anne Hendricks and Aida Nematzadeh},
  journal   = {FINDINGS},
  year      = {2021},
  doi       = {10.18653/v1/2021.findings-acl.318},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/5c09c7b9d749e7a1f90573b0cfd53606f1038d73}
}

@article{beňová2024beyond,
  title   = {Beyond Image-Text Matching: Verb Understanding in Multimodal Transformers Using Guided Masking},
  author  = {Ivana Beňová and Jana Košecká and Michal Gregor and Martin Tamajka and Marcel Veselý and Marián Šimko},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2401.16575},
  url     = {https://arxiv.org/abs/2401.16575v1},
  pdf     = {https://arxiv.org/pdf/2401.16575.pdf}
}

@article{Salin_Farah_Ayache_Favre_2022, title={Are Vision-Language Transformers Learning Multimodal Representations? A Probing Perspective}, volume={36}, url={https://ojs.aaai.org/index.php/AAAI/article/view/21375}, DOI={10.1609/aaai.v36i10.21375}, abstractNote={In recent years, joint text-image embeddings have significantly improved thanks to the development of transformer-based Vision-Language models. Despite these advances, we still need to better understand the representations produced by those models. In this paper, we compare pre-trained and fine-tuned representations at a vision, language and multimodal level. To that end, we use a set of probing tasks to evaluate the performance of state-of-the-art Vision-Language models and introduce new datasets specifically for multimodal probing. These datasets are carefully designed to address a range of multimodal capabilities while minimizing the potential for models to rely on bias. Although the results confirm the ability of Vision-Language models to understand color at a multimodal level, the models seem to prefer relying on bias in text data for object position and size. On semantically adversarial examples, we find that those models are able to pinpoint fine-grained multimodal differences. Finally, we also notice that fine-tuning a Vision-Language model on multimodal tasks does not necessarily improve its multimodal ability. We make all datasets and code available to replicate experiments.}, number={10}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Salin, Emmanuelle and Farah, Badreddine and Ayache, Stéphane and Favre, Benoit}, year={2022}, month={Jun.}, pages={11248-11257} }

@inproceedings{kajic2022probing,
  title     = {Probing Representations of Numbers in Vision and Language Models},
  author    = {Ivana Kajic and Aida Nematzadeh},
  booktitle = {SVRHM 2022 Workshop @ NeurIPS},
  year      = {2022},
  url       = {https://openreview.net/forum?id=01hQQ16Lc9M},
  pdf       = {https://openreview.net/pdf?id=01hQQ16Lc9M}
}

@article{pantazopoulos2024lost,
  title     = {Lost in Space: Probing Fine-grained Spatial Understanding in Vision and Language Resamplers},
  author    = {Georgios Pantazopoulos and Alessandro Suglia and Oliver Lemon and Arash Eshghi},
  journal   = {North American Chapter of the Association for Computational Linguistics},
  year      = {2024},
  doi       = {10.48550/arXiv.2404.13594},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/79bbcfc461722e63bd25c80679c8af51bf90359d}
}

@article{templeton2024scaling,
       title={Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
       author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
       year={2024},
       journal={Transformer Circuits Thread},
       url={https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}
    }

@article{gao2024scaling,
  title   = {Scaling and evaluating sparse autoencoders},
  author  = {Leo Gao and Tom Dupré la Tour and Henk Tillman and Gabriel Goh and Rajan Troll and Alec Radford and Ilya Sutskever and Jan Leike and Jeffrey Wu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2406.04093},
  url     = {https://arxiv.org/abs/2406.04093v1},
  pdf     = {https://arxiv.org/pdf/2406.04093.pdf}
}

@misc{dunefsky2024transcoders,
  author = {Jacob Dunefsky and Philippe Chlenski and Neel Nanda},
  title  = {Transcoders enable fine-grained interpretable circuit analysis for language models — LessWrong},
  year   = {2024},
  url    = {https://www.lesswrong.com/posts/YmkjnWtZGLbHRbzrP/transcoders-enable-fine-grained-interpretable-circuit},
  note   = {Accessed 2024-11-19},
  pdf    = {https://www.lesswrong.com/posts/YmkjnWtZGLbHRbzrP/transcoders-enable-fine-grained-interpretable-circuit}
}

@misc{lindsey2024sparse,
  author = {Jack Lindsey* and Adly Templeton* and Jonathan Marcus* and Thomas Conerly* and Joshua Batson and Christopher Olah},
  title  = {Sparse Crosscoders for Cross-Layer Features and Model Diffing},
  year   = {2024},
  url    = {https://transformer-circuits.pub/2024/crosscoders/index.html},
  note   = {Accessed 2024-11-19},
  pdf    = {https://transformer-circuits.pub/2024/crosscoders/index.html}
}

@inproceedings{DBLP:conf/iclr/HubenCRES24,
  author    = {Robert Huben and Hoagy Cunningham and Logan Riggs and Aidan Ewart and Lee Sharkey},
  title     = {Sparse Autoencoders Find Highly Interpretable Features in Language Models},
  booktitle = {The Twelfth International Conference on Learning Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher = {OpenReview.net},
  year      = {2024},
  url       = {https://openreview.net/forum?id=F76bwRSLeK},
  timestamp = {Wed, 07 Aug 2024 17:11:53 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/HubenCRES24.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  pdf       = {https://arxiv.org/pdf/2309.08600.pdf}
}

@misc{ewingtonpitsos2024suite,
  author = {Louka Ewington-Pitsos and RRGoyal},
  title  = {A suite of Vision Sparse Autoencoders — LessWrong},
  year   = {2024},
  url    = {https://www.lesswrong.com/posts/wrznNDMRmbQABAEMH/a-suite-of-vision-sparse-autoencoders},
  note   = {Accessed 2024-11-19},
  pdf    = {https://www.lesswrong.com/posts/wrznNDMRmbQABAEMH/a-suite-of-vision-sparse-autoencoders}
}

@misc{joseph2023vit,
  author = {Sonia Joseph},
  title = {ViT Prisma: A Mechanistic Interpretability Library for Vision Transformers},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/soniajoseph/vit-prisma}}
}

@inproceedings{DBLP:conf/emnlp/MosbachGBKG24,
  author    = {Marius Mosbach and Vagrant Gautam and Tom{\'{a}}s Vergara Browne and Dietrich Klakow and Mor Geva},
  editor    = {Yaser Al{-}Onaizan and Mohit Bansal and Yun{-}Nung Chen},
  title     = {From Insights to Actions: The Impact of Interpretability and Analysis Research on {NLP}},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, {EMNLP} 2024, Miami, FL, USA, November 12-16, 2024},
  pages     = {3078-3105},
  publisher = {Association for Computational Linguistics},
  year      = {2024},
  url       = {https://aclanthology.org/2024.emnlp-main.181},
  timestamp = {Thu, 14 Nov 2024 17:20:54 +0100},
  biburl    = {https://dblp.org/rec/conf/emnlp/MosbachGBKG24.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  pdf       = {https://arxiv.org/pdf/2406.12618.pdf}
}

@article{basu2024understanding,
  title   = {Understanding Information Storage and Transfer in Multi-modal Large Language Models},
  author  = {Samyadeep Basu and Martin Grayson and Cecily Morrison and Besmira Nushi and Soheil Feizi and Daniela Massiceti},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2406.04236}
}

@misc{bills2023language,
         title={Language models can explain neurons in language models},
         author={
            Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William
         },
         year={2023},
         howpublished = {\url{https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html}}
      }

@inproceedings{DBLP:conf/blackboxnlp/HuangGDWP23,
  author    = {Jing Huang and Atticus Geiger and Karel D'Oosterlinck and Zhengxuan Wu and Christopher Potts},
  editor    = {Yonatan Belinkov and Sophie Hao and Jaap Jumelet and Najoung Kim and Arya McCarthy and Hosein Mohebbi},
  title     = {Rigorously Assessing Natural Language Explanations of Neurons},
  booktitle = {Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP@EMNLP 2023, Singapore, December 7, 2023},
  pages     = {317-331},
  publisher = {Association for Computational Linguistics},
  year      = {2023},
  url       = {https://doi.org/10.18653/v1/2023.blackboxnlp-1.24},
  doi       = {10.18653/V1/2023.BLACKBOXNLP-1.24},
  timestamp = {Sun, 06 Oct 2024 20:57:07 +0200},
  biburl    = {https://dblp.org/rec/conf/blackboxnlp/HuangGDWP23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hernandez2022natural,
  title     = {Natural Language Descriptions of Deep Visual Features},
  author    = {Evan Hernandez and Sarah Schwettmann and David Bau and Teona Bagashvili and A. Torralba and Jacob Andreas},
  journal   = {International Conference on Learning Representations},
  year      = {2022},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/2e7be2911be7c6c8b8016aa30953d479649f1ffe}
}

@article{holtzman2023generative,
  title   = {Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?},
  author  = {Ari Holtzman and Peter West and Luke Zettlemoyer},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2308.00189},
  url     = {https://arxiv.org/abs/2308.00189v1},
  pdf     = {https://arxiv.org/pdf/2308.00189.pdf}
}

@article{anwar2024foundational,
  title   = {Foundational Challenges in Assuring Alignment and Safety of Large Language Models},
  author  = {Usman Anwar and Abulhair Saparov and Javier Rando and Daniel Paleka and Miles Turpin and Peter Hase and Ekdeep Singh Lubana and Erik Jenner and Stephen Casper and Oliver Sourbut and Benjamin L. Edelman and Zhaowei Zhang and Mario Günther and Anton Korinek and Jose Hernandez-Orallo and Lewis Hammond and Eric Bigelow and Alexander Pan and Lauro Langosco and Tomasz Korbak and Heidi Zhang and Ruiqi Zhong and Seán Ó hÉigeartaigh and Gabriel Recchia and Giulio Corsi and Alan Chan and Markus Anderljung and Lilian Edwards and Aleksandar Petrov and Christian Schroeder de Witt and Sumeet Ramesh Motwan and Yoshua Bengio and Danqi Chen and Philip H. S. Torr and Samuel Albanie and Tegan Maharaj and Jakob Foerster and Florian Tramer and He He and Atoosa Kasirzadeh and Yejin Choi and David Krueger},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2404.09932},
  url     = {https://arxiv.org/abs/2404.09932v2},
  pdf     = {https://arxiv.org/pdf/2404.09932.pdf}
}

@article{singh2023explaining,
  title   = {Explaining black box text modules in natural language with language models},
  author  = {Chandan Singh and Aliyah R. Hsu and Richard Antonello and Shailee Jain and Alexander G. Huth and Bin Yu and Jianfeng Gao},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2305.09863}
}

@inproceedings{atanasova-etal-2023-faithfulness,
  title     = {Faithfulness Tests for Natural Language Explanations},
  author    = {Atanasova, Pepa and Camburu, Oana-Maria and Lioma, Christina and Lukasiewicz, Thomas and Simonsen, Jakob Grue and Augenstein, Isabelle},
  editor    = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month     = {jul},
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-short.25},
  doi       = {10.18653/v1/2023.acl-short.25},
  pages     = {283-294},
  abstract  = {Explanations of neural models aim to reveal a model{'}s decision-making process for its predictions. However, recent work shows that current methods giving explanations such as saliency maps or counterfactuals can be misleading, as they are prone to present reasons that are unfaithful to the model{'}s inner workings. This work explores the challenging question of evaluating the faithfulness of natural language explanations (NLEs). To this end, we present two tests. First, we propose a counterfactual input editor for inserting reasons that lead to counterfactual predictions but are not reflected by the NLEs. Second, we reconstruct inputs from the reasons stated in the generated NLEs and check how often they lead to the same predictions. Our tests can evaluate emerging NLE models, proving a fundamental tool in the development of faithful NLEs.},
  pdf       = {https://aclanthology.org/2023.acl-short.25.pdf}
}

@article{bhalla2024interpreting,
  title   = {Interpreting CLIP with Sparse Linear Concept Embeddings (SpLiCE)},
  author  = {Usha Bhalla and Alex Oesterling and Suraj Srinivas and Flavio P. Calmon and Himabindu Lakkaraju},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2402.10376}
}

@article{kim2017interpretability,
  title     = {Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)},
  author    = {Been Kim and M. Wattenberg and J. Gilmer and Carrie J. Cai and James Wexler and F. Viégas and R. Sayres},
  journal   = {International Conference on Machine Learning},
  year      = {2017},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/682b9d2212258fd5edbfca589c86390c31a956b0},
  url       = {https://arxiv.org/abs/1711.11279v5},
  pdf       = {https://arxiv.org/pdf/1711.11279.pdf}
}

@inproceedings{NEURIPS2022_702f4db7,
  author    = {Liang, Victor Weixin and Zhang, Yuhui and Kwon, Yongchan and Yeung, Serena and Zou, James Y},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {17612-17625},
  publisher = {Curran Associates, Inc.},
  title     = {Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/702f4db7543a7432431df588d57bc7c9-Paper-Conference.pdf},
  volume    = {35},
  year      = {2022},
  pdf       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/702f4db7543a7432431df588d57bc7c9-Abstract-Conference.html}
}

@inproceedings{2023GPT4VisionSC,
  title={GPT-4V(ision) System Card},
  author={},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:263218031}
}

@article{Qwen2VL,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{Qwen-VL,
  title={Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@article{chen2024far,
    title={How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites},
    author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
    journal={arXiv preprint arXiv:2404.16821},
    year={2024}
  }

@article{chen2023internvl,
      title={InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks},
      author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and Li, Bin and Luo, Ping and Lu, Tong and Qiao, Yu and Dai, Jifeng},
      journal={arXiv preprint arXiv:2312.14238},
      year={2023}
  }

@InProceedings{Yue_2024_CVPR,
    author    = {Yue, Xiang and Ni, Yuansheng and Zhang, Kai and Zheng, Tianyu and Liu, Ruoqi and Zhang, Ge and Stevens, Samuel and Jiang, Dongfu and Ren, Weiming and Sun, Yuxuan and Wei, Cong and Yu, Botao and Yuan, Ruibin and Sun, Renliang and Yin, Ming and Zheng, Boyuan and Yang, Zhenzhu and Liu, Yibo and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu},
    title     = {MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {9556-9567}
}

@article{yue2024mmmupro,
  title   = {MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark},
  author  = {Xiang Yue and Tianyu Zheng and Yuansheng Ni and Yubo Wang and Kai Zhang and Shengbang Tong and Yuxuan Sun and Botao Yu and Ge Zhang and Huan Sun and Yu Su and Wenhu Chen and Graham Neubig},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.02813}
}

@misc{lu2024deepseekvl,
      title={DeepSeek-VL: Towards Real-World Vision-Language Understanding},
      author={Haoyu Lu and Wen Liu and Bo Zhang and Bingxuan Wang and Kai Dong and Bo Liu and Jingxiang Sun and Tongzheng Ren and Zhuoshu Li and Hao Yang and Yaofeng Sun and Chengqi Deng and Hanwei Xu and Zhenda Xie and Chong Ruan},
      year={2024},
      eprint={2403.05525},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{team2023gemini,
  title   = {Gemini: A Family of Highly Capable Multimodal Models},
  author  = {Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M. Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R. Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W. Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco and Adrià Puigdomènech Badia and David Reitter and Mianna Chen and Jenny Brennan and Clara Rivera and Sergey Brin and Shariq Iqbal and Gabriela Surita and Jane Labanowski and Abhi Rao and Stephanie Winkler and Emilio Parisotto and Yiming Gu and Kate Olszewska and Ravi Addanki and Antoine Miech and Annie Louis and Denis Teplyashin and Geoff Brown and Elliot Catt and Jan Balaguer and Jackie Xiang and Pidong Wang and Zoe Ashwood and Anton Briukhov and Albert Webson and Sanjay Ganapathy and Smit Sanghavi and Ajay Kannan and Ming-Wei Chang and Axel Stjerngren and Josip Djolonga and Yuting Sun and Ankur Bapna and Matthew Aitchison and Pedram Pejman and Henryk Michalewski and Tianhe Yu and Cindy Wang and Juliette Love and Junwhan Ahn and Dawn Bloxwich and Kehang Han and Peter Humphreys and Thibault Sellam and James Bradbury and Varun Godbole and Sina Samangooei and Bogdan Damoc and Alex Kaskasoli and Sébastien M. R. Arnold and Vijay Vasudevan and Shubham Agrawal and Jason Riesa and Dmitry Lepikhin and Richard Tanburn and Srivatsan Srinivasan and Hyeontaek Lim and Sarah Hodkinson and Pranav Shyam and Johan Ferret and Steven Hand and Ankush Garg and Tom Le Paine and Jian Li and Yujia Li and Minh Giang and Alexander Neitz and Zaheer Abbas and Sarah York and Machel Reid and Elizabeth Cole and Aakanksha Chowdhery and Dipanjan Das and Dominika Rogozińska and Vitaliy Nikolaev and Pablo Sprechmann and Zachary Nado and Lukas Zilka and Flavien Prost and Luheng He and Marianne Monteiro and Gaurav Mishra and Chris Welty and Josh Newlan and Dawei Jia and Miltiadis Allamanis and Clara Huiyi Hu and Raoul de Liedekerke and Justin Gilmer and Carl Saroufim and Shruti Rijhwani and Shaobo Hou and Disha Shrivastava and Anirudh Baddepudi and Alex Goldin and Adnan Ozturel and Albin Cassirer and Yunhan Xu and Daniel Sohn and Devendra Sachan and Reinald Kim Amplayo and Craig Swanson and Dessie Petrova and Shashi Narayan and Arthur Guez and Siddhartha Brahma and Jessica Landon and Miteyan Patel and Ruizhe Zhao and Kevin Villela and Luyu Wang and Wenhao Jia and Matthew Rahtz and Mai Giménez and Legg Yeung and James Keeling and Petko Georgiev and Diana Mincu and Boxi Wu and Salem Haykal and Rachel Saputro and Kiran Vodrahalli and James Qin and Zeynep Cankara and Abhanshu Sharma and Nick Fernando and Will Hawkins and Behnam Neyshabur and Solomon Kim and Adrian Hutter and Priyanka Agrawal and Alex Castro-Ros and George van den Driessche and Tao Wang and Fan Yang and Shuo-yiin Chang and Paul Komarek and Ross McIlroy and Mario Lučić and Guodong Zhang and Wael Farhan and Michael Sharman and Paul Natsev and Paul Michel and Yamini Bansal and Siyuan Qiao and Kris Cao and Siamak Shakeri and Christina Butterfield and Justin Chung and Paul Kishan Rubenstein and Shivani Agrawal and Arthur Mensch and Kedar Soparkar and Karel Lenc and Timothy Chung and Aedan Pope and Loren Maggiore and Jackie Kay and Priya Jhakra and Shibo Wang and Joshua Maynez and Mary Phuong and Taylor Tobin and Andrea Tacchetti and Maja Trebacz and Kevin Robinson and Yash Katariya and Sebastian Riedel and Paige Bailey and Kefan Xiao and Nimesh Ghelani and Lora Aroyo and Ambrose Slone and Neil Houlsby and Xuehan Xiong and Zhen Yang and Elena Gribovskaya and Jonas Adler and Mateo Wirth and Lisa Lee and Music Li and Thais Kagohara and Jay Pavagadhi and Sophie Bridgers and Anna Bortsova and Sanjay Ghemawat and Zafarali Ahmed and Tianqi Liu and Richard Powell and Vijay Bolina and Mariko Iinuma and Polina Zablotskaia and James Besley and Da-Woon Chung and Timothy Dozat and Ramona Comanescu and Xiance Si and Jeremy Greer and Guolong Su and Martin Polacek and Raphaël Lopez Kaufman and Simon Tokumine and Hexiang Hu and Elena Buchatskaya and Yingjie Miao and Mohamed Elhawaty and Aditya Siddhant and Nenad Tomasev and Jinwei Xing and Christina Greer and Helen Miller and Shereen Ashraf and Aurko Roy and Zizhao Zhang and Ada Ma and Angelos Filos and Milos Besta and Rory Blevins and Ted Klimenko and Chih-Kuan Yeh and Soravit Changpinyo and Jiaqi Mu and Oscar Chang and Mantas Pajarskas and Carrie Muir and Vered Cohen and Charline Le Lan and Krishna Haridasan and Amit Marathe and Steven Hansen and Sholto Douglas and Rajkumar Samuel and Mingqiu Wang and Sophia Austin and Chang Lan and Jiepu Jiang and Justin Chiu and Jaime Alonso Lorenzo and Lars Lowe Sjösund and Sébastien Cevey and Zach Gleicher and Thi Avrahami and Anudhyan Boral and Hansa Srinivasan and Vittorio Selo and Rhys May and Konstantinos Aisopos and Léonard Hussenot and Livio Baldini Soares and Kate Baumli and Michael B. Chang and Adrià Recasens and Ben Caine and Alexander Pritzel and Filip Pavetic and Fabio Pardo and Anita Gergely and Justin Frye and Vinay Ramasesh and Dan Horgan and Kartikeya Badola and Nora Kassner and Subhrajit Roy and Ethan Dyer and Víctor Campos Campos and Alex Tomala and Yunhao Tang and Dalia El Badawy and Elspeth White and Basil Mustafa and Oran Lang and Abhishek Jindal and Sharad Vikram and Zhitao Gong and Sergi Caelles and Ross Hemsley and Gregory Thornton and Fangxiaoyu Feng and Wojciech Stokowiec and Ce Zheng and Phoebe Thacker and Çağlar Ünlü and Zhishuai Zhang and Mohammad Saleh and James Svensson and Max Bileschi and Piyush Patil and Ankesh Anand and Roman Ring and Katerina Tsihlas and Arpi Vezer and Marco Selvi and Toby Shevlane and Mikel Rodriguez and Tom Kwiatkowski and Samira Daruki and Keran Rong and Allan Dafoe and Nicholas FitzGerald and Keren Gu-Lemberg and Mina Khan and Lisa Anne Hendricks and Marie Pellat and Vladimir Feinberg and James Cobon-Kerr and Tara Sainath and Maribeth Rauh and Sayed Hadi Hashemi and Richard Ives and Yana Hasson and Eric Noland and Yuan Cao and Nathan Byrd and Le Hou and Qingze Wang and Thibault Sottiaux and Michela Paganini and Jean-Baptiste Lespiau and Alexandre Moufarek and Samer Hassan and Kaushik Shivakumar and Joost van Amersfoort and Amol Mandhane and Pratik Joshi and Anirudh Goyal and Matthew Tung and Andrew Brock and Hannah Sheahan and Vedant Misra and Cheng Li and Nemanja Rakićević and Mostafa Dehghani and Fangyu Liu and Sid Mittal and Junhyuk Oh and Seb Noury and Eren Sezener and Fantine Huot and Matthew Lamm and Nicola De Cao and Charlie Chen and Sidharth Mudgal and Romina Stella and Kevin Brooks and Gautam Vasudevan and Chenxi Liu and Mainak Chain and Nivedita Melinkeri and Aaron Cohen and Venus Wang and Kristie Seymore and Sergey Zubkov and Rahul Goel and Summer Yue and Sai Krishnakumaran and Brian Albert and Nate Hurley and Motoki Sano and Anhad Mohananey and Jonah Joughin and Egor Filonov and Tomasz Kępa and Yomna Eldawy and Jiawern Lim and Rahul Rishi and Shirin Badiezadegan and Taylor Bos and Jerry Chang and Sanil Jain and Sri Gayatri Sundara Padmanabhan and Subha Puttagunta and Kalpesh Krishna and Leslie Baker and Norbert Kalb and Vamsi Bedapudi and Adam Kurzrok and Shuntong Lei and Anthony Yu and Oren Litvin and Xiang Zhou and Zhichun Wu and Sam Sobell and Andrea Siciliano and Alan Papir and Robby Neale and Jonas Bragagnolo and Tej Toor and Tina Chen and Valentin Anklin and Feiran Wang and Richie Feng and Milad Gholami and Kevin Ling and Lijuan Liu and Jules Walter and Hamid Moghaddam and Arun Kishore and Jakub Adamek and Tyler Mercado and Jonathan Mallinson and Siddhinita Wandekar and Stephen Cagle and Eran Ofek and Guillermo Garrido and Clemens Lombriser and Maksim Mukha and Botu Sun and Hafeezul Rahman Mohammad and Josip Matak and Yadi Qian and Vikas Peswani and Pawel Janus and Quan Yuan and Leif Schelin and Oana David and Ankur Garg and Yifan He and Oleksii Duzhyi and Anton Älgmyr and Timothée Lottaz and Qi Li and Vikas Yadav and Luyao Xu and Alex Chinien and Rakesh Shivanna and Aleksandr Chuklin and Josie Li and Carrie Spadine and Travis Wolfe and Kareem Mohamed and Subhabrata Das and Zihang Dai and Kyle He and Daniel von Dincklage and Shyam Upadhyay and Akanksha Maurya and Luyan Chi and Sebastian Krause and Khalid Salama and Pam G Rabinovitch and Pavan Kumar Reddy M and Aarush Selvan and Mikhail Dektiarev and Golnaz Ghiasi and Erdem Guven and Himanshu Gupta and Boyi Liu and Deepak Sharma and Idan Heimlich Shtacher and Shachi Paul and Oscar Akerlund and François-Xavier Aubet and Terry Huang and Chen Zhu and Eric Zhu and Elico Teixeira and Matthew Fritze and Francesco Bertolini and Liana-Eleonora Marinescu and Martin Bölle and Dominik Paulus and Khyatti Gupta and Tejasi Latkar and Max Chang and Jason Sanders and Roopa Wilson and Xuewei Wu and Yi-Xuan Tan and Lam Nguyen Thiet and Tulsee Doshi and Sid Lall and Swaroop Mishra and Wanming Chen and Thang Luong and Seth Benjamin and Jasmine Lee and Ewa Andrejczuk and Dominik Rabiej and Vipul Ranjan and Krzysztof Styrc and Pengcheng Yin and Jon Simon and Malcolm Rose Harriott and Mudit Bansal and Alexei Robsky and Geoff Bacon and David Greene and Daniil Mirylenka and Chen Zhou and Obaid Sarvana and Abhimanyu Goyal and Samuel Andermatt and Patrick Siegler and Ben Horn and Assaf Israel and Francesco Pongetti and Chih-Wei "Louis" Chen and Marco Selvatici and Pedro Silva and Kathie Wang and Jackson Tolins and Kelvin Guu and Roey Yogev and Xiaochen Cai and Alessandro Agostini and Maulik Shah and Hung Nguyen and Noah Ó Donnaile and Sébastien Pereira and Linda Friso and Adam Stambler and Adam Kurzrok and Chenkai Kuang and Yan Romanikhin and Mark Geller and ZJ Yan and Kane Jang and Cheng-Chun Lee and Wojciech Fica and Eric Malmi and Qijun Tan and Dan Banica and Daniel Balle and Ryan Pham and Yanping Huang and Diana Avram and Hongzhi Shi and Jasjot Singh and Chris Hidey and Niharika Ahuja and Pranab Saxena and Dan Dooley and Srividya Pranavi Potharaju and Eileen O'Neill and Anand Gokulchandran and Ryan Foley and Kai Zhao and Mike Dusenberry and Yuan Liu and Pulkit Mehta and Ragha Kotikalapudi and Chalence Safranek-Shrader and Andrew Goodman and Joshua Kessinger and Eran Globen and Prateek Kolhar and Chris Gorgolewski and Ali Ibrahim and Yang Song and Ali Eichenbaum and Thomas Brovelli and Sahitya Potluri and Preethi Lahoti and Cip Baetu and Ali Ghorbani and Charles Chen and Andy Crawford and Shalini Pal and Mukund Sridhar and Petru Gurita and Asier Mujika and Igor Petrovski and Pierre-Louis Cedoz and Chenmei Li and Shiyuan Chen and Niccolò Dal Santo and Siddharth Goyal and Jitesh Punjabi and Karthik Kappaganthu and Chester Kwak and Pallavi LV and Sarmishta Velury and Himadri Choudhury and Jamie Hall and Premal Shah and Ricardo Figueira and Matt Thomas and Minjie Lu and Ting Zhou and Chintu Kumar and Thomas Jurdi and Sharat Chikkerur and Yenai Ma and Adams Yu and Soo Kwak and Victor Ähdel and Sujeevan Rajayogam and Travis Choma and Fei Liu and Aditya Barua and Colin Ji and Ji Ho Park and Vincent Hellendoorn and Alex Bailey and Taylan Bilal and Huanjie Zhou and Mehrdad Khatir and Charles Sutton and Wojciech Rzadkowski and Fiona Macintosh and Konstantin Shagin and Paul Medina and Chen Liang and Jinjing Zhou and Pararth Shah and Yingying Bi and Attila Dankovics and Shipra Banga and Sabine Lehmann and Marissa Bredesen and Zifan Lin and John Eric Hoffmann and Jonathan Lai and Raynald Chung and Kai Yang and Nihal Balani and Arthur Bražinskas and Andrei Sozanschi and Matthew Hayes and Héctor Fernández Alcalde and Peter Makarov and Will Chen and Antonio Stella and Liselotte Snijders and Michael Mandl and Ante Kärrman and Paweł Nowak and Xinyi Wu and Alex Dyck and Krishnan Vaidyanathan and Raghavender R and Jessica Mallet and Mitch Rudominer and Eric Johnston and Sushil Mittal and Akhil Udathu and Janara Christensen and Vishal Verma and Zach Irving and Andreas Santucci and Gamaleldin Elsayed and Elnaz Davoodi and Marin Georgiev and Ian Tenney and Nan Hua and Geoffrey Cideron and Edouard Leurent and Mahmoud Alnahlawi and Ionut Georgescu and Nan Wei and Ivy Zheng and Dylan Scandinaro and Heinrich Jiang and Jasper Snoek and Mukund Sundararajan and Xuezhi Wang and Zack Ontiveros and Itay Karo and Jeremy Cole and Vinu Rajashekhar and Lara Tumeh and Eyal Ben-David and Rishub Jain and Jonathan Uesato and Romina Datta and Oskar Bunyan and Shimu Wu and John Zhang and Piotr Stanczyk and Ye Zhang and David Steiner and Subhajit Naskar and Michael Azzam and Matthew Johnson and Adam Paszke and Chung-Cheng Chiu and Jaume Sanchez Elias and Afroz Mohiuddin and Faizan Muhammad and Jin Miao and Andrew Lee and Nino Vieillard and Jane Park and Jiageng Zhang and Jeff Stanway and Drew Garmon and Abhijit Karmarkar and Zhe Dong and Jong Lee and Aviral Kumar and Luowei Zhou and Jonathan Evens and William Isaac and Geoffrey Irving and Edward Loper and Michael Fink and Isha Arkatkar and Nanxin Chen and Izhak Shafran and Ivan Petrychenko and Zhe Chen and Johnson Jia and Anselm Levskaya and Zhenkai Zhu and Peter Grabowski and Yu Mao and Alberto Magni and Kaisheng Yao and Javier Snaider and Norman Casagrande and Evan Palmer and Paul Suganthan and Alfonso Castaño and Irene Giannoumis and Wooyeol Kim and Mikołaj Rybiński and Ashwin Sreevatsa and Jennifer Prendki and David Soergel and Adrian Goedeckemeyer and Willi Gierke and Mohsen Jafari and Meenu Gaba and Jeremy Wiesner and Diana Gage Wright and Yawen Wei and Harsha Vashisht and Yana Kulizhskaya and Jay Hoover and Maigo Le and Lu Li and Chimezie Iwuanyanwu and Lu Liu and Kevin Ramirez and Andrey Khorlin and Albert Cui and Tian LIN and Marcus Wu and Ricardo Aguilar and Keith Pallo and Abhishek Chakladar and Ginger Perng and Elena Allica Abellan and Mingyang Zhang and Ishita Dasgupta and Nate Kushman and Ivo Penchev and Alena Repina and Xihui Wu and Tom van der Weide and Priya Ponnapalli and Caroline Kaplan and Jiri Simsa and Shuangfeng Li and Olivier Dousse and Fan Yang and Jeff Piper and Nathan Ie and Rama Pasumarthi and Nathan Lintz and Anitha Vijayakumar and Daniel Andor and Pedro Valenzuela and Minnie Lui and Cosmin Paduraru and Daiyi Peng and Katherine Lee and Shuyuan Zhang and Somer Greene and Duc Dung Nguyen and Paula Kurylowicz and Cassidy Hardin and Lucas Dixon and Lili Janzer and Kiam Choo and Ziqiang Feng and Biao Zhang and Achintya Singhal and Dayou Du and Dan McKinnon and Natasha Antropova and Tolga Bolukbasi and Orgad Keller and David Reid and Daniel Finchelstein and Maria Abi Raad and Remi Crocker and Peter Hawkins and Robert Dadashi and Colin Gaffney and Ken Franko and Anna Bulanova and Rémi Leblond and Shirley Chung and Harry Askham and Luis C. Cobo and Kelvin Xu and Felix Fischer and Jun Xu and Christina Sorokin and Chris Alberti and Chu-Cheng Lin and Colin Evans and Alek Dimitriev and Hannah Forbes and Dylan Banarse and Zora Tung and Mark Omernick and Colton Bishop and Rachel Sterneck and Rohan Jain and Jiawei Xia and Ehsan Amid and Francesco Piccinno and Xingyu Wang and Praseem Banzal and Daniel J. Mankowitz and Alex Polozov and Victoria Krakovna and Sasha Brown and MohammadHossein Bateni and Dennis Duan and Vlad Firoiu and Meghana Thotakuri and Tom Natan and Matthieu Geist and Ser tan Girgin and Hui Li and Jiayu Ye and Ofir Roval and Reiko Tojo and Michael Kwong and James Lee-Thorp and Christopher Yew and Danila Sinopalnikov and Sabela Ramos and John Mellor and Abhishek Sharma and Kathy Wu and David Miller and Nicolas Sonnerat and Denis Vnukov and Rory Greig and Jennifer Beattie and Emily Caveness and Libin Bai and Julian Eisenschlos and Alex Korchemniy and Tomy Tsai and Mimi Jasarevic and Weize Kong and Phuong Dao and Zeyu Zheng and Frederick Liu and Fan Yang and Rui Zhu and Tian Huey Teh and Jason Sanmiya and Evgeny Gladchenko and Nejc Trdin and Daniel Toyama and Evan Rosen and Sasan Tavakkol and Linting Xue and Chen Elkind and Oliver Woodman and John Carpenter and George Papamakarios and Rupert Kemp and Sushant Kafle and Tanya Grunina and Rishika Sinha and Alice Talbert and Diane Wu and Denese Owusu-Afriyie and Cosmo Du and Chloe Thornton and Jordi Pont-Tuset and Pradyumna Narayana and Jing Li and Saaber Fatehi and John Wieting and Omar Ajmeri and Benigno Uria and Yeongil Ko and Laura Knight and Amélie Héliou and Ning Niu and Shane Gu and Chenxi Pang and Yeqing Li and Nir Levine and Ariel Stolovich and Rebeca Santamaria-Fernandez and Sonam Goenka and Wenny Yustalim and Robin Strudel and Ali Elqursh and Charlie Deck and Hyo Lee and Zonglin Li and Kyle Levin and Raphael Hoffmann and Dan Holtmann-Rice and Olivier Bachem and Sho Arora and Christy Koh and Soheil Hassas Yeganeh and Siim Põder and Mukarram Tariq and Yanhua Sun and Lucian Ionita and Mojtaba Seyedhosseini and Pouya Tafti and Zhiyu Liu and Anmol Gulati and Jasmine Liu and Xinyu Ye and Bart Chrzaszcz and Lily Wang and Nikhil Sethi and Tianrun Li and Ben Brown and Shreya Singh and Wei Fan and Aaron Parisi and Joe Stanton and Vinod Koverkathu and Christopher A. Choquette-Choo and Yunjie Li and TJ Lu and Abe Ittycheriah and Prakash Shroff and Mani Varadarajan and Sanaz Bahargam and Rob Willoughby and David Gaddy and Guillaume Desjardins and Marco Cornero and Brona Robenek and Bhavishya Mittal and Ben Albrecht and Ashish Shenoy and Fedor Moiseev and Henrik Jacobsson and Alireza Ghaffarkhah and Morgane Rivière and Alanna Walton and Clément Crepy and Alicia Parrish and Zongwei Zhou and Clement Farabet and Carey Radebaugh and Praveen Srinivasan and Claudia van der Salm and Andreas Fidjeland and Salvatore Scellato and Eri Latorre-Chimoto and Hanna Klimczak-Plucińska and David Bridson and Dario de Cesare and Tom Hudson and Piermaria Mendolicchio and Lexi Walker and Alex Morris and Matthew Mauger and Alexey Guseynov and Alison Reid and Seth Odoom and Lucia Loher and Victor Cotruta and Madhavi Yenugula and Dominik Grewe and Anastasia Petrushkina and Tom Duerig and Antonio Sanchez and Steve Yadlowsky and Amy Shen and Amir Globerson and Lynette Webb and Sahil Dua and Dong Li and Surya Bhupatiraju and Dan Hurt and Haroon Qureshi and Ananth Agarwal and Tomer Shani and Matan Eyal and Anuj Khare and Shreyas Rammohan Belle and Lei Wang and Chetan Tekur and Mihir Sanjay Kale and Jinliang Wei and Ruoxin Sang and Brennan Saeta and Tyler Liechty and Yi Sun and Yao Zhao and Stephan Lee and Pandu Nayak and Doug Fritz and Manish Reddy Vuyyuru and John Aslanides and Nidhi Vyas and Martin Wicke and Xiao Ma and Evgenii Eltyshev and Nina Martin and Hardie Cate and James Manyika and Keyvan Amiri and Yelin Kim and Xi Xiong and Kai Kang and Florian Luisier and Nilesh Tripuraneni and David Madras and Mandy Guo and Austin Waters and Oliver Wang and Joshua Ainslie and Jason Baldridge and Han Zhang and Garima Pruthi and Jakob Bauer and Feng Yang and Riham Mansour and Jason Gelman and Yang Xu and George Polovets and Ji Liu and Honglong Cai and Warren Chen and XiangHai Sheng and Emily Xue and Sherjil Ozair and Christof Angermueller and Xiaowei Li and Anoop Sinha and Weiren Wang and Julia Wiesinger and Emmanouil Koukoumidis and Yuan Tian and Anand Iyer and Madhu Gurumurthy and Mark Goldenson and Parashar Shah and MK Blake and Hongkun Yu and Anthony Urbanowicz and Jennimaria Palomaki and Chrisantha Fernando and Ken Durden and Harsh Mehta and Nikola Momchev and Elahe Rahimtoroghi and Maria Georgaki and Amit Raul and Sebastian Ruder and Morgan Redshaw and Jinhyuk Lee and Denny Zhou and Komal Jalan and Dinghua Li and Blake Hechtman and Parker Schuh and Milad Nasr and Kieran Milan and Vladimir Mikulik and Juliana Franco and Tim Green and Nam Nguyen and Joe Kelley and Aroma Mahendru and Andrea Hu and Joshua Howland and Ben Vargas and Jeffrey Hui and Kshitij Bansal and Vikram Rao and Rakesh Ghiya and Emma Wang and Ke Ye and Jean Michel Sarr and Melanie Moranski Preston and Madeleine Elish and Steve Li and Aakash Kaku and Jigar Gupta and Ice Pasupat and Da-Cheng Juan and Milan Someswar and Tejvi M. and Xinyun Chen and Aida Amini and Alex Fabrikant and Eric Chu and Xuanyi Dong and Amruta Muthal and Senaka Buthpitiya and Sarthak Jauhari and Nan Hua and Urvashi Khandelwal and Ayal Hitron and Jie Ren and Larissa Rinaldi and Shahar Drath and Avigail Dabush and Nan-Jiang Jiang and Harshal Godhia and Uli Sachs and Anthony Chen and Yicheng Fan and Hagai Taitelbaum and Hila Noga and Zhuyun Dai and James Wang and Chen Liang and Jenny Hamer and Chun-Sung Ferng and Chenel Elkind and Aviel Atias and Paulina Lee and Vít Listík and Mathias Carlen and Jan van de Kerkhof and Marcin Pikus and Krunoslav Zaher and Paul Müller and Sasha Zykova and Richard Stefanec and Vitaly Gatsko and Christoph Hirnschall and Ashwin Sethi and Xingyu Federico Xu and Chetan Ahuja and Beth Tsai and Anca Stefanoiu and Bo Feng and Keshav Dhandhania and Manish Katyal and Akshay Gupta and Atharva Parulekar and Divya Pitta and Jing Zhao and Vivaan Bhatia and Yashodha Bhavnani and Omar Alhadlaq and Xiaolin Li and Peter Danenberg and Dennis Tu and Alex Pine and Vera Filippova and Abhipso Ghosh and Ben Limonchik and Bhargava Urala and Chaitanya Krishna Lanka and Derik Clive and Yi Sun and Edward Li and Hao Wu and Kevin Hongtongsak and Ianna Li and Kalind Thakkar and Kuanysh Omarov and Kushal Majmundar and Michael Alverson and Michael Kucharski and Mohak Patel and Mudit Jain and Maksim Zabelin and Paolo Pelagatti and Rohan Kohli and Saurabh Kumar and Joseph Kim and Swetha Sankar and Vineet Shah and Lakshmi Ramachandruni and Xiangkai Zeng and Ben Bariach and Laura Weidinger and Tu Vu and Alek Andreev and Antoine He and Kevin Hui and Sheleem Kashem and Amar Subramanya and Sissie Hsiao and Demis Hassabis and Koray Kavukcuoglu and Adam Sadovsky and Quoc Le and Trevor Strohman and Yonghui Wu and Slav Petrov and Jeffrey Dean and Oriol Vinyals},
  year    = {keyword},
  journal = {THE},
  url     = {https://arxiv.org/abs/2312.11805v4},
  pdf     = {https://arxiv.org/pdf/2312.11805.pdf}
}

@inproceedings{DBLP:conf/iclr/LuBX0LH0CG024,
  author    = {Pan Lu and Hritik Bansal and Tony Xia and Jiacheng Liu and Chunyuan Li and Hannaneh Hajishirzi and Hao Cheng and Kai{-}Wei Chang and Michel Galley and Jianfeng Gao},
  title     = {MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},
  booktitle = {The Twelfth International Conference on Learning Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher = {OpenReview.net},
  year      = {2024},
  url       = {https://openreview.net/forum?id=KUNzEQMWU7},
  timestamp = {Mon, 29 Jul 2024 17:17:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LuBX0LH0CG024.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  pdf       = {https://arxiv.org/pdf/2310.02255.pdf}
}

@inproceedings{NEURIPS2022_960a172b,
  author    = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob L and Borgeaud, Sebastian and Brock, Andy and Nematzadeh, Aida and Sharifzadeh, Sahand and Bi\'{n}kowski, Miko\l aj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Kar\'{e}n},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {23716-23736},
  publisher = {Curran Associates, Inc.},
  title     = {Flamingo: a Visual Language Model for Few-Shot Learning},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/960a172bc7fbf0177ccccbb411a7d800-Paper-Conference.pdf},
  volume    = {35},
  year      = {2022},
  pdf       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html}
}

@article{awadalla2023openflamingo,
  title   = {OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models},
  author  = {Anas Awadalla and Irena Gao and Josh Gardner and Jack Hessel and Yusuf Hanafy and Wanrong Zhu and Kalyani Marathe and Yonatan Bitton and Samir Gadre and Shiori Sagawa and Jenia Jitsev and Simon Kornblith and Pang Wei Koh and Gabriel Ilharco and Mitchell Wortsman and Ludwig Schmidt},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2308.01390},
  url     = {https://arxiv.org/abs/2308.01390v2},
  pdf     = {https://arxiv.org/pdf/2308.01390.pdf}
}

@article{dai2024nvlm,
  title   = {NVLM: Open Frontier-Class Multimodal LLMs},
  author  = {Wenliang Dai and Nayeon Lee and Boxin Wang and Zhuolin Yang and Zihan Liu and Jon Barker and Tuomas Rintamaki and Mohammad Shoeybi and Bryan Catanzaro and Wei Ping},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.11402},
  url     = {https://arxiv.org/abs/2409.11402v2},
  pdf     = {https://arxiv.org/pdf/2409.11402.pdf}
}

@article{liu2023visual,
  title     = {Visual Instruction Tuning},
  author    = {Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
  journal   = {Neural Information Processing Systems},
  year      = {2023},
  doi       = {10.48550/arXiv.2304.08485},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/a5036f31f0e629dc661f120b8c3b1f374d479ab8}
}

@article{liu2023improved,
  title     = {Improved Baselines with Visual Instruction Tuning},
  author    = {Haotian Liu and Chunyuan Li and Yuheng Li and Yong Jae Lee},
  journal   = {Computer Vision and Pattern Recognition},
  year      = {2023},
  doi       = {10.1109/CVPR52733.2024.02484},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/124d4d374fbef2016fa9880489871a58a7450644}
}

@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}

@article{li2024llavaonevision,
  title   = {LLaVA-OneVision: Easy Visual Task Transfer},
  author  = {Bo Li and Yuanhan Zhang and Dong Guo and Renrui Zhang and Feng Li and Hao Zhang and Kaichen Zhang and Peiyuan Zhang and Yanwei Li and Ziwei Liu and Chunyuan Li},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2408.03326}
}

@article{dubey2024llama,
  title   = {The Llama 3 Herd of Models},
  author  = {Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaoqing Ellen Tan and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aaron Grattafiori and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alex Vaughan and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Franco and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and Danny Wyatt and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Firat Ozgenel and Francesco Caggioni and Francisco Guzmán and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Govind Thattai and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Karthik Prasad and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kun Huang and Kunal Chawla and Kushal Lakhotia and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Maria Tsimpoukelli and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikolay Pavlovich Laptev and Ning Dong and Ning Zhang and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Rohan Maheswari and Russ Howes and Ruty Rinott and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Kohler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vítor Albiero and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaofang Wang and Xiaojian Wu and Xiaolan Wang and Xide Xia and Xilun Wu and Xinbo Gao and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yuchen Hao and Yundi Qian and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2407.21783},
  url     = {https://arxiv.org/abs/2407.21783v2},
  pdf     = {https://arxiv.org/pdf/2407.21783.pdf}
}

@article{mckinzie2024mm1,
  title   = {MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training},
  author  = {Brandon McKinzie and Zhe Gan and Jean-Philippe Fauconnier and Sam Dodge and Bowen Zhang and Philipp Dufter and Dhruti Shah and Xianzhi Du and Futang Peng and Floris Weers and Anton Belyi and Haotian Zhang and Karanjeet Singh and Doug Kang and Ankur Jain and Hongyu Hè and Max Schwarzer and Tom Gunter and Xiang Kong and Aonan Zhang and Jianyu Wang and Chong Wang and Nan Du and Tao Lei and Sam Wiseman and Guoli Yin and Mark Lee and Zirui Wang and Ruoming Pang and Peter Grasch and Alexander Toshev and Yinfei Yang},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2403.09611}
}

@inproceedings{DBLP:conf/icml/RadfordKHRGASAM21,
  author    = {Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  editor    = {Marina Meila and Tong Zhang},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {8748-8763},
  publisher = {PMLR},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/radford21a.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/RadfordKHRGASAM21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{laurencon2023obelics,
      title={OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents},
      author={Hugo Laurençon and Lucile Saulnier and Léo Tronchon and Stas Bekman and Amanpreet Singh and Anton Lozhkov and Thomas Wang and Siddharth Karamcheti and Alexander M. Rush and Douwe Kiela and Matthieu Cord and Victor Sanh},
      year={2023},
      eprint={2306.16527},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@article{ye2023ureader,
  title     = {UReader: Universal OCR-free Visually-situated Language Understanding with Multimodal Large Language Model},
  author    = {Jiabo Ye and Anwen Hu and Haiyang Xu and Qinghao Ye and Mingshi Yan and Guohai Xu and Chenliang Li and Junfeng Tian and Qi Qian and Ji Zhang and Qin Jin and Liang He and Xin Lin and Feiyan Huang},
  journal   = {Conference on Empirical Methods in Natural Language Processing},
  year      = {2023},
  doi       = {10.48550/arXiv.2310.05126},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/69b90bd79bb0fc87d39180161926964ae9dd7cbc},
  url       = {https://arxiv.org/abs/2310.05126v1},
  pdf       = {https://arxiv.org/pdf/2310.05126.pdf}
}

@inproceedings{DBLP:conf/nips/LaurenconSTBSLW23,
  author    = {Hugo Lauren{\c{c}}on and Lucile Saulnier and L{\'{e}}o Tronchon and Stas Bekman and Amanpreet Singh and Anton Lozhkov and Thomas Wang and Siddharth Karamcheti and Alexander M. Rush and Douwe Kiela and Matthieu Cord and Victor Sanh},
  editor    = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
  title     = {{OBELICS:} An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents},
  booktitle = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
  year      = {2023},
  url       = {http://papers.nips.cc/paper\_files/paper/2023/hash/e2cfb719f58585f779d0a4f9f07bd618-Abstract-Datasets\_and\_Benchmarks.html},
  timestamp = {Fri, 01 Mar 2024 16:26:21 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/LaurenconSTBSLW23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{laurençon2024matters,
  title   = {What matters when building vision-language models?},
  author  = {Hugo Laurençon and Léo Tronchon and Matthieu Cord and Victor Sanh},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2405.02246},
  url     = {https://arxiv.org/abs/2405.02246v1},
  pdf     = {https://arxiv.org/pdf/2405.02246.pdf}
}

@article{lin2024moellava,
  title   = {MoE-LLaVA: Mixture of Experts for Large Vision-Language Models},
  author  = {Bin Lin and Zhenyu Tang and Yang Ye and Jiaxi Cui and Bin Zhu and Peng Jin and Jinfa Huang and Junwu Zhang and Yatian Pang and Munan Ning and Li Yuan},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2401.15947}
}

@article{laurençon2024building,
  title   = {Building and better understanding vision-language models: insights and future directions},
  author  = {Hugo Laurençon and Andrés Marafioti and Victor Sanh and Léo Tronchon},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2408.12637},
  url     = {https://arxiv.org/abs/2408.12637v1},
  pdf     = {https://arxiv.org/pdf/2408.12637.pdf}
}

@article{hu2021lora,
  title     = {LoRA: Low-Rank Adaptation of Large Language Models},
  author    = {J. E. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Weizhu Chen},
  journal   = {International Conference on Learning Representations},
  year      = {2021},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/a8ca46b171467ceb2d7652fbfb67fe701ad86092}
}

@article{yu2023rlhfv,
  title     = {RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback},
  author    = {Tianyu Yu and Yuan Yao and Haoye Zhang and Taiwen He and Yifeng Han and Ganqu Cui and Jinyi Hu and Zhiyuan Liu and Hai-Tao Zheng and Maosong Sun and Tat-Seng Chua},
  journal   = {Computer Vision and Pattern Recognition},
  year      = {2023},
  doi       = {10.1109/CVPR52733.2024.01310},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/0f9a3c5c6a54fca6be2afa0fd5fd34eed96a31e8},
  url       = {https://arxiv.org/abs/2312.00849v2},
  pdf       = {https://arxiv.org/pdf/2312.00849.pdf}
}

@article{li2023monkey,
  title     = {Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models},
  author    = {Zhang Li and Biao Yang and Qiang Liu and Zhiyin Ma and Shuo Zhang and Jingxu Yang and Yabo Sun and Yuliang Liu and Xiang Bai},
  journal   = {Computer Vision and Pattern Recognition},
  year      = {2023},
  doi       = {10.1109/CVPR52733.2024.02527},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/bf14244669d5505f63343d4365d99d24aa6c5e82},
  url       = {https://arxiv.org/abs/2311.06607v4},
  pdf       = {https://arxiv.org/pdf/2311.06607.pdf}
}

@article{team2024gemini,
  title   = {Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author  = {Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien M. R. Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan and Mateo Wirth and James Qin and Ivo Danihelka and Tulsee Doshi and Martin Chadwick and Jilin Chen and Sanil Jain and Quoc Le and Arjun Kar and Madhu Gurumurthy and Cheng Li and Ruoxin Sang and Fangyu Liu and Lampros Lamprou and Rich Munoz and Nathan Lintz and Harsh Mehta and Heidi Howard and Malcolm Reynolds and Lora Aroyo and Quan Wang and Lorenzo Blanco and Albin Cassirer and Jordan Griffith and Dipanjan Das and Stephan Lee and Jakub Sygnowski and Zach Fisher and James Besley and Richard Powell and Zafarali Ahmed and Dominik Paulus and David Reitter and Zalan Borsos and Rishabh Joshi and Aedan Pope and Steven Hand and Vittorio Selo and Vihan Jain and Nikhil Sethi and Megha Goel and Takaki Makino and Rhys May and Zhen Yang and Johan Schalkwyk and Christina Butterfield and Anja Hauth and Alex Goldin and Will Hawkins and Evan Senter and Sergey Brin and Oliver Woodman and Marvin Ritter and Eric Noland and Minh Giang and Vijay Bolina and Lisa Lee and Tim Blyth and Ian Mackinnon and Machel Reid and Obaid Sarvana and David Silver and Alexander Chen and Lily Wang and Loren Maggiore and Oscar Chang and Nithya Attaluri and Gregory Thornton and Chung-Cheng Chiu and Oskar Bunyan and Nir Levine and Timothy Chung and Evgenii Eltyshev and Xiance Si and Timothy Lillicrap and Demetra Brady and Vaibhav Aggarwal and Boxi Wu and Yuanzhong Xu and Ross McIlroy and Kartikeya Badola and Paramjit Sandhu and Erica Moreira and Wojciech Stokowiec and Ross Hemsley and Dong Li and Alex Tudor and Pranav Shyam and Elahe Rahimtoroghi and Salem Haykal and Pablo Sprechmann and Xiang Zhou and Diana Mincu and Yujia Li and Ravi Addanki and Kalpesh Krishna and Xiao Wu and Alexandre Frechette and Matan Eyal and Allan Dafoe and Dave Lacey and Jay Whang and Thi Avrahami and Ye Zhang and Emanuel Taropa and Hanzhao Lin and Daniel Toyama and Eliza Rutherford and Motoki Sano and HyunJeong Choe and Alex Tomala and Chalence Safranek-Shrader and Nora Kassner and Mantas Pajarskas and Matt Harvey and Sean Sechrist and Meire Fortunato and Christina Lyu and Gamaleldin Elsayed and Chenkai Kuang and James Lottes and Eric Chu and Chao Jia and Chih-Wei Chen and Peter Humphreys and Kate Baumli and Connie Tao and Rajkumar Samuel and Cicero Nogueira dos Santos and Anders Andreassen and Nemanja Rakićević and Dominik Grewe and Aviral Kumar and Stephanie Winkler and Jonathan Caton and Andrew Brock and Sid Dalmia and Hannah Sheahan and Iain Barr and Yingjie Miao and Paul Natsev and Jacob Devlin and Feryal Behbahani and Flavien Prost and Yanhua Sun and Artiom Myaskovsky and Thanumalayan Sankaranarayana Pillai and Dan Hurt and Angeliki Lazaridou and Xi Xiong and Ce Zheng and Fabio Pardo and Xiaowei Li and Dan Horgan and Joe Stanton and Moran Ambar and Fei Xia and Alejandro Lince and Mingqiu Wang and Basil Mustafa and Albert Webson and Hyo Lee and Rohan Anil and Martin Wicke and Timothy Dozat and Abhishek Sinha and Enrique Piqueras and Elahe Dabir and Shyam Upadhyay and Anudhyan Boral and Lisa Anne Hendricks and Corey Fry and Josip Djolonga and Yi Su and Jake Walker and Jane Labanowski and Ronny Huang and Vedant Misra and Jeremy Chen and RJ Skerry-Ryan and Avi Singh and Shruti Rijhwani and Dian Yu and Alex Castro-Ros and Beer Changpinyo and Romina Datta and Sumit Bagri and Arnar Mar Hrafnkelsson and Marcello Maggioni and Daniel Zheng and Yury Sulsky and Shaobo Hou and Tom Le Paine and Antoine Yang and Jason Riesa and Dominika Rogozinska and Dror Marcus and Dalia El Badawy and Qiao Zhang and Luyu Wang and Helen Miller and Jeremy Greer and Lars Lowe Sjos and Azade Nova and Heiga Zen and Rahma Chaabouni and Mihaela Rosca and Jiepu Jiang and Charlie Chen and Ruibo Liu and Tara Sainath and Maxim Krikun and Alex Polozov and Jean-Baptiste Lespiau and Josh Newlan and Zeyncep Cankara and Soo Kwak and Yunhan Xu and Phil Chen and Andy Coenen and Clemens Meyer and Katerina Tsihlas and Ada Ma and Juraj Gottweis and Jinwei Xing and Chenjie Gu and Jin Miao and Christian Frank and Zeynep Cankara and Sanjay Ganapathy and Ishita Dasgupta and Steph Hughes-Fitt and Heng Chen and David Reid and Keran Rong and Hongmin Fan and Joost van Amersfoort and Vincent Zhuang and Aaron Cohen and Shixiang Shane Gu and Anhad Mohananey and Anastasija Ilic and Taylor Tobin and John Wieting and Anna Bortsova and Phoebe Thacker and Emma Wang and Emily Caveness and Justin Chiu and Eren Sezener and Alex Kaskasoli and Steven Baker and Katie Millican and Mohamed Elhawaty and Kostas Aisopos and Carl Lebsack and Nathan Byrd and Hanjun Dai and Wenhao Jia and Matthew Wiethoff and Elnaz Davoodi and Albert Weston and Lakshman Yagati and Arun Ahuja and Isabel Gao and Golan Pundak and Susan Zhang and Michael Azzam and Khe Chai Sim and Sergi Caelles and James Keeling and Abhanshu Sharma and Andy Swing and YaGuang Li and Chenxi Liu and Carrie Grimes Bostock and Yamini Bansal and Zachary Nado and Ankesh Anand and Josh Lipschultz and Abhijit Karmarkar and Lev Proleev and Abe Ittycheriah and Soheil Hassas Yeganeh and George Polovets and Aleksandra Faust and Jiao Sun and Alban Rrustemi and Pen Li and Rakesh Shivanna and Jeremiah Liu and Chris Welty and Federico Lebron and Anirudh Baddepudi and Sebastian Krause and Emilio Parisotto and Radu Soricut and Zheng Xu and Dawn Bloxwich and Melvin Johnson and Behnam Neyshabur and Justin Mao-Jones and Renshen Wang and Vinay Ramasesh and Zaheer Abbas and Arthur Guez and Constant Segal and Duc Dung Nguyen and James Svensson and Le Hou and Sarah York and Kieran Milan and Sophie Bridgers and Wiktor Gworek and Marco Tagliasacchi and James Lee-Thorp and Michael Chang and Alexey Guseynov and Ale Jakse Hartman and Michael Kwong and Ruizhe Zhao and Sheleem Kashem and Elizabeth Cole and Antoine Miech and Richard Tanburn and Mary Phuong and Filip Pavetic and Sebastien Cevey and Ramona Comanescu and Richard Ives and Sherry Yang and Cosmo Du and Bo Li and Zizhao Zhang and Mariko Iinuma and Clara Huiyi Hu and Aurko Roy and Shaan Bijwadia and Zhenkai Zhu and Danilo Martins and Rachel Saputro and Anita Gergely and Steven Zheng and Dawei Jia and Ioannis Antonoglou and Adam Sadovsky and Shane Gu and Yingying Bi and Alek Andreev and Sina Samangooei and Mina Khan and Tomas Kocisky and Angelos Filos and Chintu Kumar and Colton Bishop and Adams Yu and Sarah Hodkinson and Sid Mittal and Premal Shah and Alexandre Moufarek and Yong Cheng and Adam Bloniarz and Jaehoon Lee and Pedram Pejman and Paul Michel and Stephen Spencer and Vladimir Feinberg and Xuehan Xiong and Nikolay Savinov and Charlotte Smith and Siamak Shakeri and Dustin Tran and Mary Chesus and Bernd Bohnet and George Tucker and Tamara von Glehn and Carrie Muir and Yiran Mao and Hideto Kazawa and Ambrose Slone and Kedar Soparkar and Disha Shrivastava and James Cobon-Kerr and Michael Sharman and Jay Pavagadhi and Carlos Araya and Karolis Misiunas and Nimesh Ghelani and Michael Laskin and David Barker and Qiujia Li and Anton Briukhov and Neil Houlsby and Mia Glaese and Balaji Lakshminarayanan and Nathan Schucher and Yunhao Tang and Eli Collins and Hyeontaek Lim and Fangxiaoyu Feng and Adria Recasens and Guangda Lai and Alberto Magni and Nicola De Cao and Aditya Siddhant and Zoe Ashwood and Jordi Orbay and Mostafa Dehghani and Jenny Brennan and Yifan He and Kelvin Xu and Yang Gao and Carl Saroufim and James Molloy and Xinyi Wu and Seb Arnold and Solomon Chang and Julian Schrittwieser and Elena Buchatskaya and Soroush Radpour and Martin Polacek and Skye Giordano and Ankur Bapna and Simon Tokumine and Vincent Hellendoorn and Thibault Sottiaux and Sarah Cogan and Aliaksei Severyn and Mohammad Saleh and Shantanu Thakoor and Laurent Shefey and Siyuan Qiao and Meenu Gaba and Shuo-yiin Chang and Craig Swanson and Biao Zhang and Benjamin Lee and Paul Kishan Rubenstein and Gan Song and Tom Kwiatkowski and Anna Koop and Ajay Kannan and David Kao and Parker Schuh and Axel Stjerngren and Golnaz Ghiasi and Gena Gibson and Luke Vilnis and Ye Yuan and Felipe Tiengo Ferreira and Aishwarya Kamath and Ted Klimenko and Ken Franko and Kefan Xiao and Indro Bhattacharya and Miteyan Patel and Rui Wang and Alex Morris and Robin Strudel and Vivek Sharma and Peter Choy and Sayed Hadi Hashemi and Jessica Landon and Mara Finkelstein and Priya Jhakra and Justin Frye and Megan Barnes and Matthew Mauger and Dennis Daun and Khuslen Baatarsukh and Matthew Tung and Wael Farhan and Henryk Michalewski and Fabio Viola and Felix de Chaumont Quitry and Charline Le Lan and Tom Hudson and Qingze Wang and Felix Fischer and Ivy Zheng and Elspeth White and Anca Dragan and Jean-baptiste Alayrac and Eric Ni and Alexander Pritzel and Adam Iwanicki and Michael Isard and Anna Bulanova and Lukas Zilka and Ethan Dyer and Devendra Sachan and Srivatsan Srinivasan and Hannah Muckenhirn and Honglong Cai and Amol Mandhane and Mukarram Tariq and Jack W. Rae and Gary Wang and Kareem Ayoub and Nicholas FitzGerald and Yao Zhao and Woohyun Han and Chris Alberti and Dan Garrette and Kashyap Krishnakumar and Mai Gimenez and Anselm Levskaya and Daniel Sohn and Josip Matak and Inaki Iturrate and Michael B. Chang and Jackie Xiang and Yuan Cao and Nishant Ranka and Geoff Brown and Adrian Hutter and Vahab Mirrokni and Nanxin Chen and Kaisheng Yao and Zoltan Egyed and Francois Galilee and Tyler Liechty and Praveen Kallakuri and Evan Palmer and Sanjay Ghemawat and Jasmine Liu and David Tao and Chloe Thornton and Tim Green and Mimi Jasarevic and Sharon Lin and Victor Cotruta and Yi-Xuan Tan and Noah Fiedel and Hongkun Yu and Ed Chi and Alexander Neitz and Jens Heitkaemper and Anu Sinha and Denny Zhou and Yi Sun and Charbel Kaed and Brice Hulse and Swaroop Mishra and Maria Georgaki and Sneha Kudugunta and Clement Farabet and Izhak Shafran and Daniel Vlasic and Anton Tsitsulin and Rajagopal Ananthanarayanan and Alen Carin and Guolong Su and Pei Sun and Shashank V and Gabriel Carvajal and Josef Broder and Iulia Comsa and Alena Repina and William Wong and Warren Weilun Chen and Peter Hawkins and Egor Filonov and Lucia Loher and Christoph Hirnschall and Weiyi Wang and Jingchen Ye and Andrea Burns and Hardie Cate and Diana Gage Wright and Federico Piccinini and Lei Zhang and Chu-Cheng Lin and Ionel Gog and Yana Kulizhskaya and Ashwin Sreevatsa and Shuang Song and Luis C. Cobo and Anand Iyer and Chetan Tekur and Guillermo Garrido and Zhuyun Xiao and Rupert Kemp and Huaixiu Steven Zheng and Hui Li and Ananth Agarwal and Christel Ngani and Kati Goshvadi and Rebeca Santamaria-Fernandez and Wojciech Fica and Xinyun Chen and Chris Gorgolewski and Sean Sun and Roopal Garg and Xinyu Ye and S. M. Ali Eslami and Nan Hua and Jon Simon and Pratik Joshi and Yelin Kim and Ian Tenney and Sahitya Potluri and Lam Nguyen Thiet and Quan Yuan and Florian Luisier and Alexandra Chronopoulou and Salvatore Scellato and Praveen Srinivasan and Minmin Chen and Vinod Koverkathu and Valentin Dalibard and Yaming Xu and Brennan Saeta and Keith Anderson and Thibault Sellam and Nick Fernando and Fantine Huot and Junehyuk Jung and Mani Varadarajan and Michael Quinn and Amit Raul and Maigo Le and Ruslan Habalov and Jon Clark and Komal Jalan and Kalesha Bullard and Achintya Singhal and Thang Luong and Boyu Wang and Sujeevan Rajayogam and Julian Eisenschlos and Johnson Jia and Daniel Finchelstein and Alex Yakubovich and Daniel Balle and Michael Fink and Sameer Agarwal and Jing Li and Dj Dvijotham and Shalini Pal and Kai Kang and Jaclyn Konzelmann and Jennifer Beattie and Olivier Dousse and Diane Wu and Remi Crocker and Chen Elkind and Siddhartha Reddy Jonnalagadda and Jong Lee and Dan Holtmann-Rice and Krystal Kallarackal and Rosanne Liu and Denis Vnukov and Neera Vats and Luca Invernizzi and Mohsen Jafari and Huanjie Zhou and Lilly Taylor and Jennifer Prendki and Marcus Wu and Tom Eccles and Tianqi Liu and Kavya Kopparapu and Francoise Beaufays and Christof Angermueller and Andreea Marzoca and Shourya Sarcar and Hilal Dib and Jeff Stanway and Frank Perbet and Nejc Trdin and Rachel Sterneck and Andrey Khorlin and Dinghua Li and Xihui Wu and Sonam Goenka and David Madras and Sasha Goldshtein and Willi Gierke and Tong Zhou and Yaxin Liu and Yannie Liang and Anais White and Yunjie Li and Shreya Singh and Sanaz Bahargam and Mark Epstein and Sujoy Basu and Li Lao and Adnan Ozturel and Carl Crous and Alex Zhai and Han Lu and Zora Tung and Neeraj Gaur and Alanna Walton and Lucas Dixon and Ming Zhang and Amir Globerson and Grant Uy and Andrew Bolt and Olivia Wiles and Milad Nasr and Ilia Shumailov and Marco Selvi and Francesco Piccinno and Ricardo Aguilar and Sara McCarthy and Misha Khalman and Mrinal Shukla and Vlado Galic and John Carpenter and Kevin Villela and Haibin Zhang and Harry Richardson and James Martens and Matko Bosnjak and Shreyas Rammohan Belle and Jeff Seibert and Mahmoud Alnahlawi and Brian McWilliams and Sankalp Singh and Annie Louis and Wen Ding and Dan Popovici and Lenin Simicich and Laura Knight and Pulkit Mehta and Nishesh Gupta and Chongyang Shi and Saaber Fatehi and Jovana Mitrovic and Alex Grills and Joseph Pagadora and Dessie Petrova and Danielle Eisenbud and Zhishuai Zhang and Damion Yates and Bhavishya Mittal and Nilesh Tripuraneni and Yannis Assael and Thomas Brovelli and Prateek Jain and Mihajlo Velimirovic and Canfer Akbulut and Jiaqi Mu and Wolfgang Macherey and Ravin Kumar and Jun Xu and Haroon Qureshi and Gheorghe Comanici and Jeremy Wiesner and Zhitao Gong and Anton Ruddock and Matthias Bauer and Nick Felt and Anirudh GP and Anurag Arnab and Dustin Zelle and Jonas Rothfuss and Bill Rosgen and Ashish Shenoy and Bryan Seybold and Xinjian Li and Jayaram Mudigonda and Goker Erdogan and Jiawei Xia and Jiri Simsa and Andrea Michi and Yi Yao and Christopher Yew and Steven Kan and Isaac Caswell and Carey Radebaugh and Andre Elisseeff and Pedro Valenzuela and Kay McKinney and Kim Paterson and Albert Cui and Eri Latorre-Chimoto and Solomon Kim and William Zeng and Ken Durden and Priya Ponnapalli and Tiberiu Sosea and Christopher A. Choquette-Choo and James Manyika and Brona Robenek and Harsha Vashisht and Sebastien Pereira and Hoi Lam and Marko Velic and Denese Owusu-Afriyie and Katherine Lee and Tolga Bolukbasi and Alicia Parrish and Shawn Lu and Jane Park and Balaji Venkatraman and Alice Talbert and Lambert Rosique and Yuchung Cheng and Andrei Sozanschi and Adam Paszke and Praveen Kumar and Jessica Austin and Lu Li and Khalid Salama and Wooyeol Kim and Nandita Dukkipati and Anthony Baryshnikov and Christos Kaplanis and XiangHai Sheng and Yuri Chervonyi and Caglar Unlu and Diego de Las Casas and Harry Askham and Kathryn Tunyasuvunakool and Felix Gimeno and Siim Poder and Chester Kwak and Matt Miecnikowski and Vahab Mirrokni and Alek Dimitriev and Aaron Parisi and Dangyi Liu and Tomy Tsai and Toby Shevlane and Christina Kouridi and Drew Garmon and Adrian Goedeckemeyer and Adam R. Brown and Anitha Vijayakumar and Ali Elqursh and Sadegh Jazayeri and Jin Huang and Sara Mc Carthy and Jay Hoover and Lucy Kim and Sandeep Kumar and Wei Chen and Courtney Biles and Garrett Bingham and Evan Rosen and Lisa Wang and Qijun Tan and David Engel and Francesco Pongetti and Dario de Cesare and Dongseong Hwang and Lily Yu and Jennifer Pullman and Srini Narayanan and Kyle Levin and Siddharth Gopal and Megan Li and Asaf Aharoni and Trieu Trinh and Jessica Lo and Norman Casagrande and Roopali Vij and Loic Matthey and Bramandia Ramadhana and Austin Matthews and CJ Carey and Matthew Johnson and Kremena Goranova and Rohin Shah and Shereen Ashraf and Kingshuk Dasgupta and Rasmus Larsen and Yicheng Wang and Manish Reddy Vuyyuru and Chong Jiang and Joana Ijazi and Kazuki Osawa and Celine Smith and Ramya Sree Boppana and Taylan Bilal and Yuma Koizumi and Ying Xu and Yasemin Altun and Nir Shabat and Ben Bariach and Alex Korchemniy and Kiam Choo and Olaf Ronneberger and Chimezie Iwuanyanwu and Shubin Zhao and David Soergel and Cho-Jui Hsieh and Irene Cai and Shariq Iqbal and Martin Sundermeyer and Zhe Chen and Elie Bursztein and Chaitanya Malaviya and Fadi Biadsy and Prakash Shroff and Inderjit Dhillon and Tejasi Latkar and Chris Dyer and Hannah Forbes and Massimo Nicosia and Vitaly Nikolaev and Somer Greene and Marin Georgiev and Pidong Wang and Nina Martin and Hanie Sedghi and John Zhang and Praseem Banzal and Doug Fritz and Vikram Rao and Xuezhi Wang and Jiageng Zhang and Viorica Patraucean and Dayou Du and Igor Mordatch and Ivan Jurin and Lewis Liu and Ayush Dubey and Abhi Mohan and Janek Nowakowski and Vlad-Doru Ion and Nan Wei and Reiko Tojo and Maria Abi Raad and Drew A. Hudson and Vaishakh Keshava and Shubham Agrawal and Kevin Ramirez and Zhichun Wu and Hoang Nguyen and Ji Liu and Madhavi Sewak and Bryce Petrini and DongHyun Choi and Ivan Philips and Ziyue Wang and Ioana Bica and Ankush Garg and Jarek Wilkiewicz and Priyanka Agrawal and Xiaowei Li and Danhao Guo and Emily Xue and Naseer Shaik and Andrew Leach and Sadh MNM Khan and Julia Wiesinger and Sammy Jerome and Abhishek Chakladar and Alek Wenjiao Wang and Tina Ornduff and Folake Abu and Alireza Ghaffarkhah and Marcus Wainwright and Mario Cortes and Frederick Liu and Joshua Maynez and Andreas Terzis and Pouya Samangouei and Riham Mansour and Tomasz Kępa and François-Xavier Aubet and Anton Algymr and Dan Banica and Agoston Weisz and Andras Orban and Alexandre Senges and Ewa Andrejczuk and Mark Geller and Niccolo Dal Santo and Valentin Anklin and Majd Al Merey and Martin Baeuml and Trevor Strohman and Junwen Bai and Slav Petrov and Yonghui Wu and Demis Hassabis and Koray Kavukcuoglu and Jeffrey Dean and Oriol Vinyals},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2403.05530}
}

@article{wang2024emu3,
  title   = {Emu3: Next-Token Prediction is All You Need},
  author  = {Xinlong Wang and Xiaosong Zhang and Zhengxiong Luo and Quan Sun and Yufeng Cui and Jinsheng Wang and Fan Zhang and Yueze Wang and Zhen Li and Qiying Yu and Yingli Zhao and Yulong Ao and Xuebin Min and Tao Li and Boya Wu and Bo Zhao and Bowen Zhang and Liangdong Wang and Guang Liu and Zheqi He and Xi Yang and Jingjing Liu and Yonghua Lin and Tiejun Huang and Zhongyuan Wang},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.18869},
  url     = {https://arxiv.org/abs/2409.18869v1},
  pdf     = {https://arxiv.org/pdf/2409.18869.pdf}
}

@article{rafailov2023direct,
  title     = {Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
  author    = {Rafael Rafailov and Archit Sharma and E. Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
  journal   = {Neural Information Processing Systems},
  year      = {2023},
  doi       = {10.48550/arXiv.2305.18290},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/0d1c76d45afa012ded7ab741194baf142117c495}
}

@article{sun2023aligning,
  title     = {Aligning Large Multimodal Models with Factually Augmented RLHF},
  author    = {Zhiqing Sun and Sheng Shen and Shengcao Cao and Haotian Liu and Chunyuan Li and Yikang Shen and Chuang Gan and Liangyan Gui and Yu-Xiong Wang and Yiming Yang and K. Keutzer and Trevor Darrell},
  journal   = {Annual Meeting of the Association for Computational Linguistics},
  year      = {2023},
  doi       = {10.48550/arXiv.2309.14525},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/844bb298d49ef4a07b5d4929dfdfd170f6a1d5f5}
}

@article{chen2023dress,
  title     = {DRESS: Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback},
  author    = {Yangyi Chen and Karan Sikka and Michael Cogswell and Heng Ji and Ajay Divakaran},
  journal   = {Computer Vision and Pattern Recognition},
  year      = {2023},
  doi       = {10.1109/CVPR52733.2024.01350},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/391eaeb1092c2b145ff0e5a2fa61637a42921fce}
}

@article{xue2024xgenmm,
  title   = {xGen-MM (BLIP-3): A Family of Open Large Multimodal Models},
  author  = {Le Xue and Manli Shu and Anas Awadalla and Jun Wang and An Yan and Senthil Purushwalkam and Honglu Zhou and Viraj Prabhu and Yutong Dai and Michael S Ryoo and Shrikant Kendre and Jieyu Zhang and Can Qin and Shu Zhang and Chia-Chih Chen and Ning Yu and Juntao Tan and Tulika Manoj Awalgaonkar and Shelby Heinecke and Huan Wang and Yejin Choi and Ludwig Schmidt and Zeyuan Chen and Silvio Savarese and Juan Carlos Niebles and Caiming Xiong and Ran Xu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2408.08872},
  url     = {https://arxiv.org/abs/2408.08872v2},
  pdf     = {https://arxiv.org/pdf/2408.08872.pdf}
}

@misc{fuyu-8b,
  author = {Bavishi, Rohan and Elsen, Erich and Hawthorne, Curtis and Nye, Maxwell and Odena, Augustus and Somani, Arushi and  Ta\c{s}\i{}rlar, Sa\u{g}nak},
  title = {Introducing our Multimodal Models},
  url = {https://www.adept.ai/blog/fuyu-8b},
  year = {2023}
}

@article{oquab2023dinov2,
  title     = {DINOv2: Learning Robust Visual Features without Supervision},
  author    = {M. Oquab and Timothée Darcet and Théo Moutakanni and Huy Q. Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russ Howes and Po-Yao (Bernie) Huang and Shang-Wen Li and Ishan Misra and Michael G. Rabbat and Vasu Sharma and Gabriel Synnaeve and Huijiao Xu and H. Jégou and J. Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
  journal   = {Trans. Mach. Learn. Res.},
  year      = {2023},
  doi       = {10.48550/arXiv.2304.07193},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891}
}

@article{tong2024eyes,
  title     = {Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs},
  author    = {Shengbang Tong and Zhuang Liu and Yuexiang Zhai and Yi Ma and Yann LeCun and Saining Xie},
  journal   = {Computer Vision and Pattern Recognition},
  year      = {2024},
  doi       = {10.1109/CVPR52733.2024.00914},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/ca00f4056f9039d3c1a4c3a113f5ee0527149b66}
}

@article{mathew2020docvqa,
  title     = {DocVQA: A Dataset for VQA on Document Images},
  author    = {Minesh Mathew and Dimosthenis Karatzas and R. Manmatha and C. V. Jawahar},
  journal   = {IEEE Workshop/Winter Conference on Applications of Computer Vision},
  year      = {2020},
  doi       = {10.1109/WACV48630.2021.00225},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/b40bfcf339de3f0dba08fabb2b58b9368ff4c51a}
}

@article{miller2024adding,
  title   = {Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations},
  author  = {Evan Miller},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2411.00640}
}

@misc{hastingswoodhouse2024introduction,
  author = {Sarah Hastings-Woodhouse},
  title  = {Introduction to Mechanistic Interpretability – BlueDot Impact},
  year   = {2024},
  url    = {https://aisafetyfundamentals.com/blog/introduction-to-mechanistic-interpretability/},
  note   = {Accessed 2024-11-22},
  pdf    = {https://aisafetyfundamentals.com/blog/introduction-to-mechanistic-interpretability/}
}

@article{saphra2024mechanistic,
  title   = {Mechanistic?},
  author  = {Naomi Saphra and Sarah Wiegreffe},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.09087},
  url     = {https://arxiv.org/abs/2410.09087v1},
  pdf     = {https://arxiv.org/pdf/2410.09087.pdf}
}

@article{alain2016understanding,
  title     = {Understanding intermediate layers using linear classifier probes},
  author    = {Guillaume Alain and Yoshua Bengio},
  journal   = {International Conference on Learning Representations},
  year      = {2016},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/5e23a28063b395bdaf784dc548a046885cb90cf2}
}

@inproceedings{hewitt-manning-2019-structural,
  title     = {{A} Structural Probe for Finding Syntax in Word Representations},
  author    = {Hewitt, John and Manning, Christopher D.},
  editor    = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  month     = {jun},
  year      = {2019},
  address   = {Minneapolis, Minnesota},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N19-1419},
  doi       = {10.18653/v1/N19-1419},
  pages     = {4129-4138},
  abstract  = {Recent work has improved our ability to detect linguistic knowledge in word representations. However, current methods for detecting syntactic knowledge do not test whether syntax trees are represented in their entirety. In this work, we propose a structural probe, which evaluates whether syntax trees are embedded in a linear transformation of a neural network{'}s word representation space. The probe identifies a linear transformation under which squared L2 distance encodes the distance between words in the parse tree, and one in which squared L2 norm encodes depth in the parse tree. Using our probe, we show that such transformations exist for both ELMo and BERT but not in baselines, providing evidence that entire syntax trees are embedded implicitly in deep models{'} vector geometry.},
  pdf       = {https://aclanthology.org/N19-1419.pdf}
}

@article{vatsa2023adventures,
  title     = {Adventures of Trustworthy Vision-Language Models: A Survey},
  author    = {M. Vatsa and Anubhooti Jain and Richa Singh},
  journal   = {AAAI Conference on Artificial Intelligence},
  year      = {2023},
  doi       = {10.48550/arXiv.2312.04231},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/f8c9c8f7a1c309185f430732bf075d7b266b1916},
  url       = {https://arxiv.org/abs/2312.04231v1},
  pdf       = {https://arxiv.org/pdf/2312.04231.pdf}
}

@article{chen2024evlm,
  title   = {EVLM: An Efficient Vision-Language Model for Visual Understanding},
  author  = {Kaibing Chen and Dong Shen and Hanwen Zhong and Huasong Zhong and Kui Xia and Di Xu and Wei Yuan and Yifei Hu and Bin Wen and Tianke Zhang and Changyi Liu and Dewen Fan and Huihui Xiao and Jiahong Wu and Fan Yang and Size Li and Di Zhang},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2407.14177}
}

@inproceedings{Salin2022AreVT,
  title={Are Vision-Language Transformers Learning Multimodal Representations? A Probing Perspective},
  author={Emmanuelle Salin and Badreddine Farah and S. Ayache and Benoit Favre},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:250303261}
}

@inproceedings{DBLP:conf/iclr/DarcetOMB24,
  author    = {Timoth{\'{e}}e Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski},
  title     = {Vision Transformers Need Registers},
  booktitle = {The Twelfth International Conference on Learning Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher = {OpenReview.net},
  year      = {2024},
  url       = {https://openreview.net/forum?id=2dnO3LLiJ1},
  timestamp = {Mon, 29 Jul 2024 17:17:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/DarcetOMB24.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{goldowsky-dill2023localizing,
  title   = {Localizing Model Behavior with Path Patching},
  author  = {Nicholas Goldowsky-Dill and Chris MacLeod and Lucas Sato and Aryaman Arora},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2304.05969}
}

@article{madsen2024selfexplanations,
  title     = {Are self-explanations from Large Language Models faithful?},
  author    = {Andreas Madsen and Sarath Chandar and Siva Reddy},
  journal   = {Annual Meeting of the Association for Computational Linguistics},
  year      = {2024},
  doi       = {10.48550/arXiv.2401.07927},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/3937b11717c22f62ab0b48dfd89e5dab75cedf40}
}

@article{agarwal2024faithfulness,
  title   = {Faithfulness vs. Plausibility: On the (Un)Reliability of Explanations from Large Language Models},
  author  = {Chirag Agarwal and Sree Harsha Tanneru and Himabindu Lakkaraju},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2402.04614}
}

@article{o'brien2024steering,
  title   = {Steering Language Model Refusal with Sparse Autoencoders},
  author  = {Kyle O'Brien and David Majercak and Xavier Fernandes and Richard Edgar and Jingya Chen and Harsha Nori and Dean Carignan and Eric Horvitz and Forough Poursabzi-Sangde},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2411.11296}
}

@article{olsson2022context,
   title={In-context Learning and Induction Heads},
   author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Johnston, Scott and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2022},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html}
}

@article{wei2022emergent,
  title   = {Emergent Abilities of Large Language Models},
  author  = {Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2206.07682}
}

@inproceedings{TheC3,
  title={The Claude 3 Model Family: Opus, Sonnet, Haiku},
  author={},
  url={https://api.semanticscholar.org/CorpusID:268232499}
}

@article{heimersheim2024use,
  title   = {How to use and interpret activation patching},
  author  = {Stefan Heimersheim and Neel Nanda},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2404.15255},
  url     = {https://arxiv.org/abs/2404.15255v1},
  pdf     = {https://arxiv.org/pdf/2404.15255.pdf}
}

@inproceedings{DBLP:conf/iclr/ZhangN24,
  author    = {Fred Zhang and Neel Nanda},
  title     = {Towards Best Practices of Activation Patching in Language Models: Metrics and Methods},
  booktitle = {The Twelfth International Conference on Learning Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher = {OpenReview.net},
  year      = {2024},
  url       = {https://openreview.net/forum?id=Hf17y6u9BC},
  timestamp = {Wed, 07 Aug 2024 17:11:53 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ZhangN24.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  pdf       = {https://arxiv.org/pdf/2309.16042.pdf}
}

@inproceedings{DBLP:conf/iclr/NandaCLSS23,
  author    = {Neel Nanda and Lawrence Chan and Tom Lieberum and Jess Smith and Jacob Steinhardt},
  title     = {Progress measures for grokking via mechanistic interpretability},
  booktitle = {The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher = {OpenReview.net},
  year      = {2023},
  url       = {https://openreview.net/forum?id=9XFSbDPmdW},
  timestamp = {Wed, 24 Jul 2024 16:50:34 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/NandaCLSS23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  pdf       = {https://arxiv.org/pdf/2301.05217.pdf}
}

@article{arora2016linear,
  title     = {Linear Algebraic Structure of Word Senses, with Applications to Polysemy},
  author    = {Sanjeev Arora and Yuanzhi Li and Yingyu Liang and Tengyu Ma and Andrej Risteski},
  journal   = {Transactions of the Association for Computational Linguistics},
  year      = {2016},
  doi       = {10.1162/tacl_a_00034},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/45ea9f9ae5368774d921e56e28fade358d171b2f}
}

@article{olah2020zoom,
  author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  title = {Zoom In: An Introduction to Circuits},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits/zoom-in},
  doi = {10.23915/distill.00024.001}
}

@article{ferrando2024primer,
  title   = {A Primer on the Inner Workings of Transformer-based Language Models},
  author  = {Javier Ferrando and Gabriele Sarti and Arianna Bisazza and Marta R. Costa-jussà},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2405.00208},
  url     = {https://arxiv.org/abs/2405.00208v3},
  pdf     = {https://arxiv.org/pdf/2405.00208.pdf}
}

@article{kolicic2024inherently,
  title   = {Inherently Interpretable and Uncertainty-Aware Models for Online Learning in Cyber-Security Problems},
  author  = {Benjamin Kolicic and Alberto Caron and Chris Hicks and Vasilios Mavroudis},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2411.09393},
  url     = {https://arxiv.org/abs/2411.09393v1},
  pdf     = {https://arxiv.org/pdf/2411.09393.pdf}
}

@article{singhal2023towards,
  title   = {Towards Expert-Level Medical Question Answering with Large Language Models},
  author  = {Karan Singhal and Tao Tu and Juraj Gottweis and Rory Sayres and Ellery Wulczyn and Le Hou and Kevin Clark and Stephen Pfohl and Heather Cole-Lewis and Darlene Neal and Mike Schaekermann and Amy Wang and Mohamed Amin and Sami Lachgar and Philip Mansfield and Sushant Prakash and Bradley Green and Ewa Dominowska and Blaise Aguera y Arcas and Nenad Tomasev and Yun Liu and Renee Wong and Christopher Semturs and S. Sara Mahdavi and Joelle Barral and Dale Webster and Greg S. Corrado and Yossi Matias and Shekoofeh Azizi and Alan Karthikesalingam and Vivek Natarajan},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2305.09617}
}

@article{driess2023palme,
  title     = {PaLM-E: An Embodied Multimodal Language Model},
  author    = {Danny Driess and F. Xia and Mehdi S. M. Sajjadi and Corey Lynch and Aakanksha Chowdhery and Brian Ichter and Ayzaan Wahid and Jonathan Tompson and Q. Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and P. Sermanet and Daniel Duckworth and S. Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Peter R. Florence},
  journal   = {International Conference on Machine Learning},
  year      = {2023},
  doi       = {10.48550/arXiv.2303.03378},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/38fe8f324d2162e63a967a9ac6648974fc4c66f3}
}

@article{wu2023visual,
  title   = {Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models},
  author  = {Chenfei Wu and Shengming Yin and Weizhen Qi and Xiaodong Wang and Zecheng Tang and Nan Duan},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2303.04671}
}

@article{agrawal2015vqa,
  title     = {VQA: Visual Question Answering},
  author    = {Aishwarya Agrawal and Jiasen Lu and Stanislaw Antol and Margaret Mitchell and C. L. Zitnick and Devi Parikh and Dhruv Batra},
  journal   = {International Journal of Computer Vision},
  year      = {2015},
  doi       = {10.1007/s11263-016-0966-6},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db}
}

@article{vinyals2014show,
  title     = {Show and Tell: A Neural Image Caption Generator},
  author    = {O. Vinyals and Alexander Toshev and Samy Bengio and D. Erhan},
  journal   = {Computer Vision and Pattern Recognition},
  year      = {2014},
  doi       = {10.1109/CVPR.2015.7298935},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0}
}

@inproceedings{NEURIPS2022_11332b6b,
  author    = {Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {2507-2521},
  publisher = {Curran Associates, Inc.},
  title     = {Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/11332b6b6cf4485b84afadb1352d3a9a-Paper-Conference.pdf},
  volume    = {35},
  year      = {2022}
}

@article{lieberum2024gemma,
  title   = {Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2},
  author  = {Tom Lieberum and Senthooran Rajamanoharan and Arthur Conmy and Lewis Smith and Nicolas Sonnerat and Vikrant Varma and János Kramár and Anca Dragan and Rohin Shah and Neel Nanda},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2408.05147}
}

@article{belinkov2021probing,
  title     = {Probing Classifiers: Promises, Shortcomings, and Advances},
  author    = {Yonatan Belinkov},
  journal   = {International Conference on Computational Logic},
  year      = {2021},
  doi       = {10.1162/coli_a_00422},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/3dcfa05a1c162e6cab927c5b08d0444f7b6691f4}
}

@article{elazar2021amnesic,
  title     = {Amnesic probing: Behavioral explanation with amnesic counterfactuals},
  author    = {Elazar, Yanai and Ravfogel, Shauli and Jacovi, Alon and Goldberg, Yoav},
  journal   = {Transactions of the Association for Computational Linguistics},
  volume    = {9},
  pages     = {160-175},
  year      = {2021},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{belrose2023eliciting,
  title   = {Eliciting Latent Predictions from Transformers with the Tuned Lens},
  author  = {Nora Belrose and Zach Furman and Logan Smith and Danny Halawi and Igor Ostrovsky and Lev McKinney and Stella Biderman and Jacob Steinhardt},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2303.08112}
}