@article{rafailov2024from,
  title={From {$r$} to {$Q^*$}: Your Language Model is Secretly a Q-Function},
  author={Rafailov, Rafael and Hejna, Jakub and Park, Rishabh and Mitchell, Ethan and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2404.12358},
  year={2024}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Ethan and Manning, Christopher D},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{bouneffouf2019survey,
  title={A survey on practical applications of multi-armed and contextual bandits},
  author={Bouneffouf, Djallel and Rish, Irina},
  journal={arXiv preprint arXiv:1904.10040},
  year={2019}
}

@inproceedings{knox2012reinforcement,
  title={Reinforcement learning from simultaneous human and MDP reward},
  author={Knox, W Bradley and Stone, Peter},
  booktitle={AAMAS},
  pages={475--482},
  year={2012}
}

@article{jiang2021reinforcement,
  title={Reinforcement Learning and Monte-Carlo Methods},
  author={Jiang, Nan},
  journal={University of Illinois Urbana-Champaign},
  year={2021}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}

@article{han2020asymptotic,
  title={Asymptotic theory of sparse Bradleyâ€“Terry model},
  author={Han, Rui and Ye, Yinyu and Tan, Cexun and Jiao, Jie},
  journal={The Annals of Statistics},
  volume={48},
  number={1},
  pages={521--549},
  year={2020},
  publisher={Institute of Mathematical Statistics}
}

@book{wilson2015weighted,
  title={Weighted logistic regression model},
  author={Wilson, Jessica R and Lorenz, Keith A},
  journal={Modeling Binary Correlated Responses using SAS, SPSS and R},
  pages={81--102},
  year={2015},
  publisher={Cambridge University Press}
}

@article{sewak2019policy,
  title={Policy-based reinforcement learning approaches: Stochastic policy gradient and the REINFORCE algorithm},
  author={Sewak, Mohit and Sewak, Mohit},
  journal={Deep Reinforcement Learning: Frontiers of Artificial Intelligence},
  pages={127--140},
  year={2019},
  publisher={Springer}
}

@article{konda1999actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan},
  journal={Foundations and Trends in Robotics},
  volume={2},
  number={1--2},
  pages={1--142},
  year={2013},
  publisher={Now Publishers Inc.}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Jacob and Adler, Stephen and Agarwal, Shashank and Bai, Yee Whye Teh and Balaji, Sumanth and Barreira, Brendan and Barros, Nicole and Baumli, Christopher and Beirami, Avraham and Belinkov, Yonatan and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@misc{alignmentguidebook,
  title={Alignment Guidebook},
  author={Shangmin Guo and Wei Xiong},
  url={https://www.notion.so/e5c64df77c0a4b528b7951e87337fa78?pvs=21},
  note = {Accessed: 2023-12-14}
}

@inproceedings{huggingfacearmor,
      title={Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts}, 
      author={Haoxiang Wang and Wei Xiong and Tengyang Xie and Han Zhao and Tong Zhang},
      booktitle={EMNLP},
      year={2024}
}

@article{pal2024smaug,
  title={Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive},
  author={Pal, Abhishek and Karkhanis, Deepanshu and Dooley, Sean and Lomeli, Michael and Askell, Alex and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2402.13228},
  year={2024}
}

@article{xie2024exploratory,
  title={Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF},
  author={Xie, Tengyang and Foster, Dylan J and Krishnamurthy, Akshay and Rosset, Corby and Awadallah, Ahmed and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2405.21046},
  year={2024}
}